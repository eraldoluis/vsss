<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>The PG Library: /Users/daa/legacy/src/libpg/trunk/NeuralNet.cc Source File</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.3 -->
<div class="tabs">
  <ul>
    <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
    <li><a href="namespaces.html"><span>Namespaces</span></a></li>
    <li><a href="annotated.html"><span>Classes</span></a></li>
    <li class="current"><a href="files.html"><span>Files</span></a></li>
  </ul>
</div>
<h1>/Users/daa/legacy/src/libpg/trunk/NeuralNet.cc</h1><a href="_neural_net_8cc.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00005"></a>00005 <span class="preprocessor">#include"<a class="code" href="_p_g_basics_8hh.html">PGBasics.hh</a>"</span>
<a name="l00006"></a>00006 <span class="preprocessor">#include"<a class="code" href="_neural_net_8hh.html">NeuralNet.hh</a>"</span>
<a name="l00007"></a>00007 
<a name="l00008"></a>00008 <span class="keyword">using namespace </span>std;
<a name="l00009"></a>00009 <span class="keyword">namespace </span>libpg {
<a name="l00010"></a>00010 
<a name="l00016"></a><a class="code" href="classlibpg_1_1_neural_net.html#cc380337df1d4253f4574f201a01da5c">00016</a> <a class="code" href="classlibpg_1_1_neural_net.html#cc380337df1d4253f4574f201a01da5c">NeuralNet::NeuralNet</a>(<span class="keywordtype">int</span> ins, <span class="keywordtype">int</span> outs) {
<a name="l00017"></a>00017 
<a name="l00018"></a>00018     <a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>.resize(2);
<a name="l00019"></a>00019     <a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>[0] = ins;
<a name="l00020"></a>00020     <a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>[1] = outs;
<a name="l00021"></a>00021 
<a name="l00022"></a>00022     <a class="code" href="classlibpg_1_1_neural_net.html#4111c1f220cd1e954b9028f82878ec23">squash</a>.resize(2);
<a name="l00023"></a>00023     <a class="code" href="classlibpg_1_1_neural_net.html#4111c1f220cd1e954b9028f82878ec23">squash</a>.clear();
<a name="l00024"></a>00024 
<a name="l00025"></a>00025     <a class="code" href="classlibpg_1_1_neural_net.html#922fb9883320c655a2bb5f047588bdd4">init</a>();
<a name="l00026"></a>00026 
<a name="l00027"></a>00027 }
<a name="l00028"></a>00028 
<a name="l00029"></a>00029 
<a name="l00039"></a><a class="code" href="classlibpg_1_1_neural_net.html#abe65365e72c0e9db1b48cb90968acbc">00039</a> NeuralNet::NeuralNet(<a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a>&amp; layerDims, <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a>&amp; layerSquash) {
<a name="l00040"></a>00040 
<a name="l00041"></a>00041     assert(layerSquash.size() == layerDims.size());
<a name="l00042"></a>00042     <a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a> = layerDims;
<a name="l00043"></a>00043     <a class="code" href="classlibpg_1_1_neural_net.html#4111c1f220cd1e954b9028f82878ec23">squash</a> = layerSquash;
<a name="l00044"></a>00044     <a class="code" href="classlibpg_1_1_neural_net.html#922fb9883320c655a2bb5f047588bdd4">init</a>();
<a name="l00045"></a>00045 
<a name="l00046"></a>00046 }
<a name="l00047"></a>00047 
<a name="l00048"></a>00048 
<a name="l00053"></a><a class="code" href="classlibpg_1_1_neural_net.html#922fb9883320c655a2bb5f047588bdd4">00053</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#922fb9883320c655a2bb5f047588bdd4">NeuralNet::init</a>() {
<a name="l00054"></a>00054 
<a name="l00055"></a>00055     <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a> = <a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>.size() - 1;
<a name="l00056"></a>00056 
<a name="l00057"></a>00057     assert(<a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a> &gt; 0); <span class="comment">// Need at least one layer</span>
<a name="l00058"></a>00058  
<a name="l00059"></a>00059     <a class="code" href="classlibpg_1_1_neural_net.html#9c8286f88836cfb1de4878adfc4199b9">parameters</a> = 0;
<a name="l00060"></a>00060 
<a name="l00061"></a>00061     <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a> = <span class="keyword">new</span> <a class="code" href="namespacelibpg.html#4d1c6393e8ddc5dab3bb3733d5b5cdd8">Matrix</a>[<a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>];
<a name="l00062"></a>00062     <a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a> = <span class="keyword">new</span> <a class="code" href="namespacelibpg.html#4d1c6393e8ddc5dab3bb3733d5b5cdd8">Matrix</a>[<a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>];
<a name="l00063"></a>00063     <a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a> = <span class="keyword">new</span> <a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>[<a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>-1]; <span class="comment">// last activation is output</span>
<a name="l00064"></a>00064     <a class="code" href="classlibpg_1_1_neural_net.html#b66a98345121af418d77d403108723b9">deltas</a> = <span class="keyword">new</span> <a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>[<a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>-1];
<a name="l00065"></a>00065 
<a name="l00066"></a>00066     <span class="comment">// Layer params assume a row of params for each input. Number of</span>
<a name="l00067"></a>00067     <span class="comment">// columns is number of outputs.</span>
<a name="l00068"></a>00068     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00069"></a>00069         <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l].resize((<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>(l), (<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>(l+1)); <span class="comment">// input to output </span>
<a name="l00070"></a>00070         <a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l].resize((<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>(l), (<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>(l+1));
<a name="l00071"></a>00071         <a class="code" href="classlibpg_1_1_neural_net.html#9c8286f88836cfb1de4878adfc4199b9">parameters</a>+=(int)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>[l]*(<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>[l+1];
<a name="l00072"></a>00072 
<a name="l00073"></a>00073         <span class="keywordflow">if</span> (l &lt; layers-1) {
<a name="l00074"></a>00074             <a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l].resize((<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>(l+1)); <span class="comment">// same size as layer output</span>
<a name="l00075"></a>00075             <a class="code" href="classlibpg_1_1_neural_net.html#b66a98345121af418d77d403108723b9">deltas</a>[l].resize((<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>(l+1)); <span class="comment">// same size as layer output</span>
<a name="l00076"></a>00076         }
<a name="l00077"></a>00077     }
<a name="l00078"></a>00078 
<a name="l00079"></a>00079 }
<a name="l00080"></a>00080 
<a name="l00081"></a>00081 
<a name="l00082"></a><a class="code" href="classlibpg_1_1_neural_net.html#7ae75de4516dd066a50ab34700d9603f">00082</a> <a class="code" href="classlibpg_1_1_neural_net.html#7ae75de4516dd066a50ab34700d9603f">NeuralNet::~NeuralNet</a>(){
<a name="l00083"></a>00083     
<a name="l00084"></a>00084     <span class="keyword">delete</span>[] <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>;
<a name="l00085"></a>00085     <span class="keyword">delete</span>[] <a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>;
<a name="l00086"></a>00086     <span class="keyword">delete</span>[] <a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>;
<a name="l00087"></a>00087     <span class="keyword">delete</span>[] <a class="code" href="classlibpg_1_1_neural_net.html#b66a98345121af418d77d403108723b9">deltas</a>;
<a name="l00088"></a>00088     
<a name="l00089"></a>00089 }
<a name="l00090"></a>00090 
<a name="l00091"></a>00091 
<a name="l00092"></a>00092 <span class="comment">//#define PLSQUASH</span>
<a name="l00093"></a>00093 <span class="preprocessor">#ifdef PLSQUASH</span>
<a name="l00094"></a>00094 <span class="preprocessor"></span>
<a name="l00099"></a>00099 <span class="keywordtype">void</span>
<a name="l00100"></a>00100 <a class="code" href="classlibpg_1_1_neural_net.html#af3974961b8ed46a4937bada13d941e8">NeuralNet::squashVec</a>(<a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>&amp; x)
<a name="l00101"></a>00101 {
<a name="l00102"></a>00102     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">double</span> tanh1 = 0.76159415596;
<a name="l00103"></a>00103     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">double</span> scale = 0.079245047928; <span class="comment">// (tanh(4) - tanh(1)) / (4 - 1)</span>
<a name="l00104"></a>00104 
<a name="l00105"></a>00105     Vector::iterator <a class="code" href="namespacesum_and_plot.html#97610daaf345ca7fdc1c39359036529e">i</a>;
<a name="l00106"></a>00106     <span class="keywordflow">for</span> (i = x.begin(); i != x.end(); i++) {
<a name="l00107"></a>00107         <span class="keywordflow">if</span> ((*i) &gt;= -1 &amp;&amp; (*i) &lt;= 1)
<a name="l00108"></a>00108             (*i) *= tanh1;
<a name="l00109"></a>00109         <span class="keywordflow">else</span> <span class="keywordflow">if</span> ((*i) &lt; -4)
<a name="l00110"></a>00110             (*i) = -1;
<a name="l00111"></a>00111         <span class="keywordflow">else</span> <span class="keywordflow">if</span> ((*i) &gt; 4)
<a name="l00112"></a>00112             (*i) = 1;
<a name="l00113"></a>00113         <span class="keywordflow">else</span> <span class="keywordflow">if</span> ((*i) &lt; -1)
<a name="l00114"></a>00114             (*i) = -tanh1 + ((*i) + 1) * scale;
<a name="l00115"></a>00115         <span class="keywordflow">else</span>
<a name="l00116"></a>00116             (*i) =  tanh1 + ((*i) - 1) * scale;
<a name="l00117"></a>00117     }
<a name="l00118"></a>00118 }
<a name="l00119"></a>00119 
<a name="l00123"></a>00123 <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#c048451f722a0ac30d428c30bd2ea982">NeuralNet::dSquashVec</a>(<a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>&amp; y, <a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>&amp; v) {
<a name="l00124"></a>00124 
<a name="l00125"></a>00125     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">double</span> tanh1 = 0.76159415596;
<a name="l00126"></a>00126     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">double</span> scale = 0.079245047928; <span class="comment">// (tanh(4) - tanh(1)) / (4 - 1)</span>
<a name="l00127"></a>00127 
<a name="l00128"></a>00128     <span class="keywordtype">double</span> slope;
<a name="l00129"></a>00129     Vector::iterator i;
<a name="l00130"></a>00130     <span class="keywordflow">for</span> (i = y.begin(); i != y.end(); i++) {
<a name="l00131"></a>00131         <span class="keywordflow">if</span> ((*i) &gt;= -1 &amp;&amp; (*i) &lt;= 1)
<a name="l00132"></a>00132             slope = tanh1;
<a name="l00133"></a>00133         <span class="keywordflow">else</span> <span class="keywordflow">if</span> ((*i) &lt; -4 || (*i) &gt; 4)
<a name="l00134"></a>00134             slope = 0.;
<a name="l00135"></a>00135         <span class="keywordflow">else</span>
<a name="l00136"></a>00136             slope = scale;
<a name="l00137"></a>00137         v[i.index()] *= slope;
<a name="l00138"></a>00138     }
<a name="l00139"></a>00139 
<a name="l00140"></a>00140 }
<a name="l00141"></a>00141 
<a name="l00142"></a>00142 <span class="preprocessor">#else</span>
<a name="l00143"></a>00143 <span class="preprocessor"></span>
<a name="l00147"></a><a class="code" href="classlibpg_1_1_neural_net.html#af3974961b8ed46a4937bada13d941e8">00147</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#af3974961b8ed46a4937bada13d941e8">NeuralNet::squashVec</a>(<a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>&amp; x) {
<a name="l00148"></a>00148 
<a name="l00149"></a>00149     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; x.size(); i++) {
<a name="l00150"></a>00150         x[i] = tanh(x[i]);
<a name="l00151"></a>00151     }
<a name="l00152"></a>00152 
<a name="l00153"></a>00153 }
<a name="l00154"></a>00154 
<a name="l00158"></a><a class="code" href="classlibpg_1_1_neural_net.html#c048451f722a0ac30d428c30bd2ea982">00158</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#c048451f722a0ac30d428c30bd2ea982">NeuralNet::dSquashVec</a>(<a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>&amp; x, <a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>&amp; v) {
<a name="l00159"></a>00159 
<a name="l00160"></a>00160     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; x.size(); i++) {
<a name="l00161"></a>00161         v[i] *= (1.0 - x[i]*x[i]);
<a name="l00162"></a>00162     }
<a name="l00163"></a>00163 
<a name="l00164"></a>00164 }
<a name="l00165"></a>00165 
<a name="l00166"></a>00166 <span class="preprocessor">#endif</span>
<a name="l00167"></a>00167 <span class="preprocessor"></span>
<a name="l00168"></a>00168 
<a name="l00176"></a><a class="code" href="classlibpg_1_1_neural_net.html#ef0ce63d6568ba8d84c7fa93b6449702">00176</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#ef0ce63d6568ba8d84c7fa93b6449702">NeuralNet::doApprox</a>(<a class="code" href="classlibpg_1_1_observation.html">Observation</a>&amp; obs, <a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>&amp; output) {
<a name="l00177"></a>00177 
<a name="l00178"></a>00178     assert(obs.<a class="code" href="classlibpg_1_1_observation.html#5f91729f294b2585dc380e3307e462be">getFeatures</a>().size1() == (<span class="keywordtype">unsigned</span> int)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>(0));
<a name="l00179"></a>00179     <span class="comment">// For efficiency (both space and time) we treat the single layer</span>
<a name="l00180"></a>00180     <span class="comment">// case and multi-layer cases differently, using the obs as the</span>
<a name="l00181"></a>00181     <span class="comment">// first activiation and output as the final output activation.</span>
<a name="l00182"></a>00182 
<a name="l00183"></a>00183     <span class="comment">//cout&lt;&lt;"Obs="&lt;&lt;obs.getFeatures()&lt;&lt;endl;</span>
<a name="l00184"></a>00184     <span class="comment">//cout&lt;&lt;layerParams[0];</span>
<a name="l00185"></a>00185 
<a name="l00186"></a>00186     <span class="comment">//Linear network</span>
<a name="l00187"></a>00187     <span class="keywordflow">if</span> (<a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a> &lt; 2) {
<a name="l00188"></a>00188         axpy_prod(column(obs.<a class="code" href="classlibpg_1_1_observation.html#5f91729f294b2585dc380e3307e462be">getFeatures</a>(), obs.<a class="code" href="classlibpg_1_1_observation.html#d5712ca86bc5b2bc23720f6f3a75a465">getAgent</a>()), <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[0], output, <span class="keyword">true</span>);
<a name="l00189"></a>00189         <span class="keywordflow">if</span> ((<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#4111c1f220cd1e954b9028f82878ec23">squash</a>[0])  { <a class="code" href="classlibpg_1_1_neural_net.html#af3974961b8ed46a4937bada13d941e8">squashVec</a>(output); }
<a name="l00190"></a>00190                 
<a name="l00191"></a>00191     } 
<a name="l00192"></a>00192     <span class="keywordflow">else</span> {
<a name="l00193"></a>00193         <span class="keywordtype">int</span> l=0;
<a name="l00194"></a>00194 
<a name="l00195"></a>00195         <span class="comment">// First layer</span>
<a name="l00196"></a>00196         axpy_prod(column(obs.<a class="code" href="classlibpg_1_1_observation.html#5f91729f294b2585dc380e3307e462be">getFeatures</a>(), obs.<a class="code" href="classlibpg_1_1_observation.html#d5712ca86bc5b2bc23720f6f3a75a465">getAgent</a>()), <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l],  <a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l], <span class="keyword">true</span>);
<a name="l00197"></a>00197         <span class="comment">// Squash output of first layer? A little confusing since we</span>
<a name="l00198"></a>00198         <span class="comment">// must check squash[l+1] to see if we squash activations[l]</span>
<a name="l00199"></a>00199         <span class="keywordflow">if</span> ((<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#4111c1f220cd1e954b9028f82878ec23">squash</a>[l+1]) <a class="code" href="classlibpg_1_1_neural_net.html#af3974961b8ed46a4937bada13d941e8">squashVec</a>(<a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l]);
<a name="l00200"></a>00200         l++;
<a name="l00201"></a>00201         
<a name="l00202"></a>00202         <span class="comment">// Middle layers</span>
<a name="l00203"></a>00203         <span class="keywordflow">for</span> (; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>-1; l++) {
<a name="l00204"></a>00204             axpy_prod(<a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l-1], <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l], <a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l], <span class="keyword">true</span>);
<a name="l00205"></a>00205             <span class="keywordflow">if</span> ((<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#4111c1f220cd1e954b9028f82878ec23">squash</a>[l+1]) <a class="code" href="classlibpg_1_1_neural_net.html#af3974961b8ed46a4937bada13d941e8">squashVec</a>(<a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l]);
<a name="l00206"></a>00206         }
<a name="l00207"></a>00207         
<a name="l00208"></a>00208         <span class="comment">// Output layer</span>
<a name="l00209"></a>00209         axpy_prod(<a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l-1], <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l], output, <span class="keyword">true</span>);
<a name="l00210"></a>00210         <span class="keywordflow">if</span> ((<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#4111c1f220cd1e954b9028f82878ec23">squash</a>[l+1]) <a class="code" href="classlibpg_1_1_neural_net.html#af3974961b8ed46a4937bada13d941e8">squashVec</a>(output);
<a name="l00211"></a>00211 
<a name="l00212"></a>00212     }
<a name="l00213"></a>00213 
<a name="l00214"></a>00214 }
<a name="l00215"></a>00215 
<a name="l00216"></a>00216 
<a name="l00224"></a><a class="code" href="classlibpg_1_1_neural_net.html#f55a4fafce1b19d3d35d93750e4f3bc7">00224</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#f55a4fafce1b19d3d35d93750e4f3bc7">NeuralNet::feedbackGrad</a>(<a class="code" href="classlibpg_1_1_observation.html">Observation</a>&amp; obs, <a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>&amp; outputDeltas) {
<a name="l00225"></a>00225 
<a name="l00226"></a>00226     <span class="comment">// Single layer case</span>
<a name="l00227"></a>00227     <span class="keywordflow">if</span> (<a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a> &lt; 2) {
<a name="l00228"></a>00228         <span class="comment">// rank one update = outer produc of two vectors</span>
<a name="l00229"></a>00229         <span class="comment">// Compute grad for only layer</span>
<a name="l00230"></a>00230         noalias(<a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[0]) += outer_prod(column(obs.<a class="code" href="classlibpg_1_1_observation.html#5f91729f294b2585dc380e3307e462be">getFeatures</a>(), obs.<a class="code" href="classlibpg_1_1_observation.html#d5712ca86bc5b2bc23720f6f3a75a465">getAgent</a>()), outputDeltas);
<a name="l00231"></a>00231     }
<a name="l00232"></a>00232     <span class="keywordflow">else</span> {
<a name="l00233"></a>00233         <span class="keywordtype">int</span> l = <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a> - 1;
<a name="l00234"></a>00234 
<a name="l00235"></a>00235         <span class="comment">// Compute grad for last layer</span>
<a name="l00236"></a>00236         noalias(<a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l]) += outer_prod(<a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l-1], outputDeltas);
<a name="l00237"></a>00237         <span class="comment">// Back prop deltas through last layer</span>
<a name="l00238"></a>00238         axpy_prod(<a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l], outputDeltas, <a class="code" href="classlibpg_1_1_neural_net.html#b66a98345121af418d77d403108723b9">deltas</a>[l-1], <span class="keyword">true</span>);
<a name="l00239"></a>00239         
<a name="l00240"></a>00240         <span class="comment">// Feedback through squashing</span>
<a name="l00241"></a>00241         <span class="comment">// activations[0] is OUTPUT of first layer</span>
<a name="l00242"></a>00242         <span class="keywordflow">if</span> ((<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#4111c1f220cd1e954b9028f82878ec23">squash</a>[l]) <a class="code" href="classlibpg_1_1_neural_net.html#c048451f722a0ac30d428c30bd2ea982">dSquashVec</a>(<a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l-1], <a class="code" href="classlibpg_1_1_neural_net.html#b66a98345121af418d77d403108723b9">deltas</a>[l-1]);
<a name="l00243"></a>00243         l--;
<a name="l00244"></a>00244 
<a name="l00245"></a>00245         <span class="comment">// repeat for all hidden layers</span>
<a name="l00246"></a>00246         <span class="keywordflow">for</span> (; l &gt; 0; l--) {
<a name="l00247"></a>00247             <span class="comment">// Compute grad for current layer</span>
<a name="l00248"></a>00248             noalias(<a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l]) += outer_prod(<a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l-1], <a class="code" href="classlibpg_1_1_neural_net.html#b66a98345121af418d77d403108723b9">deltas</a>[l]);
<a name="l00249"></a>00249             <span class="comment">// Back prop deltas through current layer</span>
<a name="l00250"></a>00250             axpy_prod(<a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l], <a class="code" href="classlibpg_1_1_neural_net.html#b66a98345121af418d77d403108723b9">deltas</a>[l], <a class="code" href="classlibpg_1_1_neural_net.html#b66a98345121af418d77d403108723b9">deltas</a>[l-1], <span class="keyword">true</span>);
<a name="l00251"></a>00251             <span class="comment">// Feedback through squashing</span>
<a name="l00252"></a>00252             <span class="keywordflow">if</span> ((<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#4111c1f220cd1e954b9028f82878ec23">squash</a>[l]) <a class="code" href="classlibpg_1_1_neural_net.html#c048451f722a0ac30d428c30bd2ea982">dSquashVec</a>(<a class="code" href="classlibpg_1_1_neural_net.html#3f89c86d60d37c2d56c5bcf06f221259">activations</a>[l-1], <a class="code" href="classlibpg_1_1_neural_net.html#b66a98345121af418d77d403108723b9">deltas</a>[l-1]);
<a name="l00253"></a>00253         }
<a name="l00254"></a>00254 
<a name="l00255"></a>00255         <span class="comment">// Compute grad for input layer</span>
<a name="l00256"></a>00256         noalias(<a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l]) += outer_prod(column(obs.<a class="code" href="classlibpg_1_1_observation.html#5f91729f294b2585dc380e3307e462be">getFeatures</a>(), obs.<a class="code" href="classlibpg_1_1_observation.html#d5712ca86bc5b2bc23720f6f3a75a465">getAgent</a>()), <a class="code" href="classlibpg_1_1_neural_net.html#b66a98345121af418d77d403108723b9">deltas</a>[l]);
<a name="l00257"></a>00257         
<a name="l00258"></a>00258     }
<a name="l00259"></a>00259 
<a name="l00260"></a>00260 }
<a name="l00261"></a>00261 
<a name="l00262"></a>00262 
<a name="l00266"></a><a class="code" href="classlibpg_1_1_neural_net.html#7c89bff6ca884372f06302359e009b4d">00266</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#7c89bff6ca884372f06302359e009b4d">NeuralNet::discountTrace</a>() {
<a name="l00267"></a>00267     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00268"></a>00268         <a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l] *= <a class="code" href="classlibpg_1_1_neural_net.html#d03fc3df342f55087ca0bb0487d5257c">discount</a>;
<a name="l00269"></a>00269     }
<a name="l00270"></a>00270 
<a name="l00271"></a>00271 }
<a name="l00272"></a>00272 
<a name="l00273"></a>00273 
<a name="l00277"></a><a class="code" href="classlibpg_1_1_neural_net.html#c256ec5e75c9f24cf248ec192d82e7bb">00277</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#c256ec5e75c9f24cf248ec192d82e7bb">NeuralNet::setDiscount</a>(<span class="keywordtype">double</span> <a class="code" href="classlibpg_1_1_neural_net.html#d03fc3df342f55087ca0bb0487d5257c">discount</a>){ 
<a name="l00278"></a>00278     this-&gt;discount = discount;
<a name="l00279"></a>00279 }
<a name="l00280"></a>00280 
<a name="l00281"></a>00281 
<a name="l00288"></a><a class="code" href="classlibpg_1_1_neural_net.html#fa5c23abc593979c41e62368f22d4085">00288</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#fa5c23abc593979c41e62368f22d4085">NeuralNet::instantStep</a>(<span class="keywordtype">double</span> reward){
<a name="l00289"></a>00289  
<a name="l00290"></a>00290     <span class="keywordtype">double</span> multiplier = reward*<a class="code" href="classlibpg_1_1_neural_net.html#d35312cb8c82c6e9c7a1b80307b45080">stepSize</a>;
<a name="l00291"></a>00291     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00292"></a>00292         noalias(<a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l]) += multiplier*<a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l];
<a name="l00293"></a>00293     }
<a name="l00294"></a>00294 }
<a name="l00295"></a>00295 
<a name="l00296"></a>00296 
<a name="l00297"></a>00297 
<a name="l00302"></a><a class="code" href="classlibpg_1_1_neural_net.html#94610fad33a9ae36dd08159d7acf9114">00302</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#94610fad33a9ae36dd08159d7acf9114">NeuralNet::setStepSize</a>(<span class="keywordtype">double</span> <a class="code" href="classlibpg_1_1_neural_net.html#d35312cb8c82c6e9c7a1b80307b45080">stepSize</a>){ 
<a name="l00303"></a>00303     this-&gt;stepSize = stepSize;
<a name="l00304"></a>00304 }
<a name="l00305"></a>00305 
<a name="l00306"></a>00306 
<a name="l00311"></a><a class="code" href="classlibpg_1_1_neural_net.html#dea850cce198e7be67c5f8c340d09536">00311</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#dea850cce198e7be67c5f8c340d09536">NeuralNet::resetTrace</a>() { 
<a name="l00312"></a>00312     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00313"></a>00313         <a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l].clear();
<a name="l00314"></a>00314     }
<a name="l00315"></a>00315 
<a name="l00316"></a>00316 }
<a name="l00317"></a>00317 
<a name="l00318"></a>00318 
<a name="l00325"></a><a class="code" href="classlibpg_1_1_neural_net.html#14c23da0c58961574b618b72c2eda994">00325</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#14c23da0c58961574b618b72c2eda994">NeuralNet::resetParams</a>() { 
<a name="l00326"></a>00326     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00327"></a>00327         <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l].clear();
<a name="l00328"></a>00328     }
<a name="l00329"></a>00329 }
<a name="l00330"></a>00330 
<a name="l00331"></a>00331 
<a name="l00337"></a><a class="code" href="classlibpg_1_1_neural_net.html#86a6a435abbfa5d01a18a13ec43a6deb">00337</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#86a6a435abbfa5d01a18a13ec43a6deb">NeuralNet::randomizeParams</a>(<span class="keywordtype">double</span> maxRand) { 
<a name="l00338"></a>00338 
<a name="l00339"></a>00339   <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00340"></a>00340         <a class="code" href="classlibpg_1_1_u_blas_extras.html#98db9b05c4913b50d276087d738725df">UBlasExtras::randomize</a>(<a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l], maxRand);
<a name="l00341"></a>00341     }
<a name="l00342"></a>00342  
<a name="l00343"></a>00343 }
<a name="l00344"></a>00344 
<a name="l00345"></a>00345 
<a name="l00349"></a><a class="code" href="classlibpg_1_1_neural_net.html#8555ca7a22827345913a614475a93a00">00349</a> <span class="keywordtype">double</span> <a class="code" href="classlibpg_1_1_neural_net.html#8555ca7a22827345913a614475a93a00">NeuralNet::getMaxParam</a>() {
<a name="l00350"></a>00350     
<a name="l00351"></a>00351     <span class="keywordtype">double</span> maxi = 0.0;
<a name="l00352"></a>00352     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00353"></a>00353         maxi = <a class="code" href="namespacesum_and_plot.html#b34c7ed3d2093e608255697877c346c6">std::max</a>(maxi, (<span class="keywordtype">double</span>)norm_inf(<a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l]));
<a name="l00354"></a>00354     }
<a name="l00355"></a>00355 
<a name="l00356"></a>00356     <span class="keywordflow">return</span> maxi;
<a name="l00357"></a>00357 }
<a name="l00358"></a>00358 
<a name="l00359"></a>00359 
<a name="l00364"></a>00364 <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#2f6a7bf05959a3cce906a53afc770d23">NeuralNet::write</a>(ostream&amp; o) {
<a name="l00365"></a>00365 
<a name="l00366"></a>00366     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00367"></a>00367         o&lt;&lt;<a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l]&lt;&lt;endl;
<a name="l00368"></a>00368     }
<a name="l00369"></a>00369 
<a name="l00370"></a>00370 }
<a name="l00371"></a>00371 
<a name="l00372"></a>00372 
<a name="l00377"></a>00377 <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#c39421acbac4a4f56b3cc6a82b7c0204">NeuralNet::read</a>(istream&amp; o) {
<a name="l00378"></a>00378 
<a name="l00379"></a>00379     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00380"></a>00380         o&gt;&gt;<a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l];
<a name="l00381"></a>00381     }
<a name="l00382"></a>00382 
<a name="l00383"></a>00383 }
<a name="l00384"></a>00384 
<a name="l00385"></a>00385 
<a name="l00386"></a><a class="code" href="classlibpg_1_1_neural_net.html#3ae96be16b1271b7d1d60985ec299115">00386</a> <span class="keywordtype">int</span> <a class="code" href="classlibpg_1_1_neural_net.html#3ae96be16b1271b7d1d60985ec299115">NeuralNet::getNumParams</a>() {
<a name="l00387"></a>00387     <span class="keywordflow">return</span> <a class="code" href="classlibpg_1_1_neural_net.html#9c8286f88836cfb1de4878adfc4199b9">parameters</a>;
<a name="l00388"></a>00388 }
<a name="l00389"></a>00389 
<a name="l00390"></a>00390 
<a name="l00391"></a><a class="code" href="classlibpg_1_1_neural_net.html#3a1ad04bbff20e8c0845c5e5a705c621">00391</a> <span class="keywordtype">int</span> <a class="code" href="classlibpg_1_1_neural_net.html#3a1ad04bbff20e8c0845c5e5a705c621">NeuralNet::getInputDim</a>() {
<a name="l00392"></a>00392     <span class="keywordflow">return</span> (<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>[0];
<a name="l00393"></a>00393 }
<a name="l00394"></a>00394 
<a name="l00395"></a>00395 
<a name="l00396"></a><a class="code" href="classlibpg_1_1_neural_net.html#65269a55c07f4d86747f3f0ac7a88570">00396</a> <span class="keywordtype">int</span> <a class="code" href="classlibpg_1_1_neural_net.html#65269a55c07f4d86747f3f0ac7a88570">NeuralNet::getOutputDim</a>() {
<a name="l00397"></a>00397     <span class="keywordflow">return</span> (<span class="keywordtype">int</span>)<a class="code" href="classlibpg_1_1_neural_net.html#03f8b8d95ac6767dcccf9eff3d6e6052">dims</a>[<a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>];
<a name="l00398"></a>00398 }
<a name="l00399"></a>00399 
<a name="l00400"></a>00400 
<a name="l00404"></a><a class="code" href="classlibpg_1_1_neural_net.html#d93bda7242ffa41ade164a53d4f80c04">00404</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#d93bda7242ffa41ade164a53d4f80c04">NeuralNet::reduce</a>(<a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>&amp; v, <a class="code" href="classlibpg_1_1_approximator.html#c1375d461c4e531da046f2fad93287df">StatsEnum</a> <a class="code" href="namespacesum_and_plot.html#603763aecd0551b8cd9fc4892c55fd3f">s</a>) {
<a name="l00405"></a>00405 
<a name="l00406"></a>00406     assert(v.size() &gt;= (size_t)<a class="code" href="classlibpg_1_1_neural_net.html#9c8286f88836cfb1de4878adfc4199b9">parameters</a>);
<a name="l00407"></a>00407 
<a name="l00408"></a>00408     <span class="keywordtype">int</span> p = 0;
<a name="l00409"></a>00409 
<a name="l00410"></a>00410     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00411"></a>00411         <span class="keywordflow">switch</span> (s) {
<a name="l00412"></a>00412             <span class="keywordflow">case</span> <a class="code" href="classlibpg_1_1_approximator.html#c1375d461c4e531da046f2fad93287dfb4a4e13e0991d5d3942b37364537cad6">PARAMS</a>: 
<a name="l00413"></a>00413                 <a class="code" href="classlibpg_1_1_u_blas_extras.html#5aff66b358c0b9646cb82b562068fc1b">UBlasExtras::addMatrixToVector</a>(<a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l], v, p);
<a name="l00414"></a>00414                 <span class="keywordflow">break</span>;
<a name="l00415"></a>00415             <span class="keywordflow">case</span> <a class="code" href="classlibpg_1_1_approximator.html#c1375d461c4e531da046f2fad93287df58fce20b78385b9d157540c66e5da98d">TRACES</a>:
<a name="l00416"></a>00416                 <a class="code" href="classlibpg_1_1_u_blas_extras.html#5aff66b358c0b9646cb82b562068fc1b">UBlasExtras::addMatrixToVector</a>(<a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l], v, p);
<a name="l00417"></a>00417                 <span class="keywordflow">break</span>;
<a name="l00418"></a>00418             <span class="keywordflow">default</span>:
<a name="l00419"></a>00419                 <span class="keywordflow">throw</span> runtime_error(<span class="stringliteral">"NeuralNet::reduce() unknown type\n"</span>);
<a name="l00420"></a>00420         }
<a name="l00421"></a>00421         p += <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l].size1()*<a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l].size2();
<a name="l00422"></a>00422     }    
<a name="l00423"></a>00423     assert(p == <a class="code" href="classlibpg_1_1_neural_net.html#9c8286f88836cfb1de4878adfc4199b9">parameters</a>);
<a name="l00424"></a>00424 }
<a name="l00425"></a>00425 
<a name="l00426"></a>00426 
<a name="l00430"></a><a class="code" href="classlibpg_1_1_neural_net.html#31a7a3bb072ee6533f9f9145beb0830e">00430</a> <span class="keywordtype">void</span> <a class="code" href="classlibpg_1_1_neural_net.html#31a7a3bb072ee6533f9f9145beb0830e">NeuralNet::scatter</a>(<a class="code" href="namespacelibpg.html#62a7899983d918844e93181266713e82">Vector</a>&amp; v, <a class="code" href="classlibpg_1_1_approximator.html#c1375d461c4e531da046f2fad93287df">StatsEnum</a> <a class="code" href="namespacesum_and_plot.html#603763aecd0551b8cd9fc4892c55fd3f">s</a>) {
<a name="l00431"></a>00431 
<a name="l00432"></a>00432     assert(v.size()==(size_t)<a class="code" href="classlibpg_1_1_neural_net.html#9c8286f88836cfb1de4878adfc4199b9">parameters</a>);
<a name="l00433"></a>00433 
<a name="l00434"></a>00434     <span class="keywordtype">int</span> p = 0;
<a name="l00435"></a>00435 
<a name="l00436"></a>00436     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l=0; l &lt; <a class="code" href="classlibpg_1_1_neural_net.html#32b69a048a503b1687cfd4697a94918f">layers</a>; l++) {
<a name="l00437"></a>00437         
<a name="l00438"></a>00438         <span class="keywordflow">switch</span> (s) {
<a name="l00439"></a>00439             <span class="keywordflow">case</span> <a class="code" href="classlibpg_1_1_approximator.html#c1375d461c4e531da046f2fad93287dfb4a4e13e0991d5d3942b37364537cad6">PARAMS</a>:
<a name="l00440"></a>00440                 <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l].clear();
<a name="l00441"></a>00441                 <a class="code" href="classlibpg_1_1_u_blas_extras.html#df6e35b9be5a7e0d91d41845f23e083e">UBlasExtras::addScaledVectorToMatrix</a>(1.0, v, <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l], p);
<a name="l00442"></a>00442                 <span class="keywordflow">break</span>;
<a name="l00443"></a>00443             <span class="keywordflow">case</span> <a class="code" href="classlibpg_1_1_approximator.html#c1375d461c4e531da046f2fad93287df58fce20b78385b9d157540c66e5da98d">TRACES</a>:
<a name="l00444"></a>00444                 <a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l].clear();
<a name="l00445"></a>00445                 <a class="code" href="classlibpg_1_1_u_blas_extras.html#df6e35b9be5a7e0d91d41845f23e083e">UBlasExtras::addScaledVectorToMatrix</a>(1.0, v, <a class="code" href="classlibpg_1_1_neural_net.html#5c9b5e7e34d529b2eece251c30e8ff03">layerTraces</a>[l], p);
<a name="l00446"></a>00446                 <span class="keywordflow">break</span>;
<a name="l00447"></a>00447             <span class="keywordflow">default</span>:
<a name="l00448"></a>00448                 <span class="keywordflow">throw</span> runtime_error(<span class="stringliteral">"NeuralNet::reduce() unknown type\n"</span>);
<a name="l00449"></a>00449         }
<a name="l00450"></a>00450             
<a name="l00451"></a>00451         p += <a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l].size1()*<a class="code" href="classlibpg_1_1_neural_net.html#17b1c88b9c1c2135b51412bb3f5627ae">layerParams</a>[l].size2();
<a name="l00452"></a>00452     }    
<a name="l00453"></a>00453     assert(p == <a class="code" href="classlibpg_1_1_neural_net.html#9c8286f88836cfb1de4878adfc4199b9">parameters</a>);
<a name="l00454"></a>00454 
<a name="l00455"></a>00455 }
<a name="l00456"></a>00456 }
</pre></div><hr size="1"><address style="text-align: right;"><small>Generated on Mon Sep 10 19:32:08 2007 for The PG Library by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.3 </small></address>
</body>
</html>
