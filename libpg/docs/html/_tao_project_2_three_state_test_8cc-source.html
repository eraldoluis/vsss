<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>The PG Library: /Users/daa/legacy/src/libpg/trunk/simulators/TaoProject/ThreeStateTest.cc Source File</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.3 -->
<div class="tabs">
  <ul>
    <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
    <li><a href="namespaces.html"><span>Namespaces</span></a></li>
    <li><a href="annotated.html"><span>Classes</span></a></li>
    <li class="current"><a href="files.html"><span>Files</span></a></li>
  </ul>
</div>
<h1>/Users/daa/legacy/src/libpg/trunk/simulators/TaoProject/ThreeStateTest.cc</h1><a href="_tao_project_2_three_state_test_8cc.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="preprocessor">#include&lt;<a class="code" href="_p_g_basics_8hh.html">PGBasics.hh</a>&gt;</span>
<a name="l00002"></a>00002 <span class="preprocessor">#include"<a class="code" href="_tao_project_2_three_state_8hh.html">ThreeState.hh</a>"</span>
<a name="l00003"></a>00003 <span class="preprocessor">#include"<a class="code" href="_lookup_table_8hh.html">LookupTable.hh</a>"</span>
<a name="l00004"></a>00004 <span class="preprocessor">#include"<a class="code" href="_lookup_table_batch_8hh.html">LookupTableBatch.hh</a>"</span>
<a name="l00005"></a>00005 <span class="preprocessor">#include"<a class="code" href="_neural_net_8hh.html">NeuralNet.hh</a>"</span>
<a name="l00006"></a>00006 <span class="preprocessor">#include"<a class="code" href="_neural_net_batch_8hh.html">NeuralNetBatch.hh</a>"</span>
<a name="l00007"></a>00007 <span class="preprocessor">#include"<a class="code" href="_n_a_c_transform_8hh.html">NACTransform.hh</a>"</span>
<a name="l00008"></a>00008 
<a name="l00009"></a>00009 <span class="comment">// Policies</span>
<a name="l00010"></a>00010 <span class="preprocessor">#include"<a class="code" href="_softmax_policy_8hh.html">SoftmaxPolicy.hh</a>"</span>
<a name="l00011"></a>00011 <span class="preprocessor">#include"<a class="code" href="e_greedy_policy_8hh.html">eGreedyPolicy.hh</a>"</span>
<a name="l00012"></a>00012 
<a name="l00013"></a>00013 <span class="comment">// Controllers</span>
<a name="l00014"></a>00014 <span class="preprocessor">#include"<a class="code" href="_basic_controller_8hh.html">BasicController.hh</a>"</span>
<a name="l00015"></a>00015 <span class="preprocessor">#include"<a class="code" href="_binary_controller_8hh.html">BinaryController.hh</a>"</span>
<a name="l00016"></a>00016 <span class="preprocessor">#include"<a class="code" href="_value_controller_8hh.html">ValueController.hh</a>"</span>
<a name="l00017"></a>00017 <span class="preprocessor">#include"<a class="code" href="_s_a_r_s_a_controller_8hh.html">SARSAController.hh</a>"</span>
<a name="l00018"></a>00018 <span class="preprocessor">#include"<a class="code" href="_q_learning_controller_8hh.html">QLearningController.hh</a>"</span>
<a name="l00019"></a>00019 <span class="preprocessor">#include"<a class="code" href="_factored_controller_8hh.html">FactoredController.hh</a>"</span>
<a name="l00020"></a>00020 <span class="preprocessor">#include"LSPIController.hh"</span>
<a name="l00021"></a>00021 <span class="preprocessor">#include"<a class="code" href="_o_l_b_f_g_s_8hh.html">OLBFGS.hh</a>"</span>
<a name="l00022"></a>00022 
<a name="l00023"></a>00023 <span class="comment">// RL Algorithms</span>
<a name="l00024"></a>00024 <span class="preprocessor">#include"<a class="code" href="_o_l_pomdp_8hh.html">OLPomdp.hh</a>"</span>
<a name="l00025"></a>00025 <span class="preprocessor">#include"<a class="code" href="_g_pomdp_8hh.html">GPomdp.hh</a>"</span>
<a name="l00026"></a>00026 <span class="preprocessor">#include"<a class="code" href="_line_search_alg_8hh.html">LineSearchAlg.hh</a>"</span>
<a name="l00027"></a>00027 
<a name="l00028"></a>00028 <span class="keyword">using namespace </span>std;
<a name="l00029"></a>00029 <span class="keyword">using namespace </span>libpg;
<a name="l00030"></a>00030 
<a name="l00031"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#df579b0668a161d0ac966509f378a08d">00031</a> <span class="preprocessor">#define TD_DISCOUNT 0.6</span>
<a name="l00032"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#8c324bb806c51b79c1e30b5a3c80d3fe">00032</a> <span class="preprocessor"></span><span class="preprocessor">#define STEPS_PER_EPOCH 10000</span>
<a name="l00033"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#a0414caef00a64a51d4c6c0711d9e70a">00033</a> <span class="preprocessor"></span><span class="preprocessor">#define MAX_STEPS 1000000</span>
<a name="l00034"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#5320d4457a472d8888ec1905bc0e0a1c">00034</a> <span class="preprocessor"></span><span class="preprocessor">#define MAX_TIME 0</span>
<a name="l00035"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#773fba130cdfa9a0dba95ee0c76862c6">00035</a> <span class="preprocessor"></span><span class="preprocessor">#define TEST_RUNS 1</span>
<a name="l00036"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#42d8249c71df0cfa9839aad0e8f583d7">00036</a> <span class="preprocessor"></span><span class="preprocessor">#define NN_LAYERS 2 // includes input dimension and output dimension</span>
<a name="l00037"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#ac4cbf64d7084205e04bc1b1569baf05">00037</a> <span class="preprocessor"></span><span class="preprocessor">#define PARAM_FILE "ThreeState.params"</span>
<a name="l00038"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#7bc1af4c33fb07fbd428f4359a9796b6">00038</a> <span class="preprocessor"></span><span class="preprocessor">#define MAX_RAND_PARAM 0.00</span>
<a name="l00039"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#4d21079c4be880d193a8b3b7df9c467b">00039</a> <span class="preprocessor"></span><span class="preprocessor">#define APPROX_OUTPUTS 2</span>
<a name="l00040"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#0eef36d721ed3a84124556f2929e81eb">00040</a> <span class="preprocessor"></span><span class="preprocessor">#define LINE_SEARCH_STEPS 20</span>
<a name="l00041"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#30c17564229ec2e37dfea9c6c9ad643e">00041</a> <span class="preprocessor"></span><span class="preprocessor">#define TOLERANCE 1e-9</span>
<a name="l00042"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#fb6d30e5f89a2a1749e4a9a896716ef4">00042</a> <span class="preprocessor"></span><span class="preprocessor">#define BACKOFF 3.0</span>
<a name="l00043"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#12de296cc2e5fedc31307a31c2f6dc97">00043</a> <span class="preprocessor"></span><span class="preprocessor">#define EXPONENT_BASE 2.0 </span>
<a name="l00044"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#fd63d23830ad86d01b6fff2e6c615f7e">00044</a> <span class="preprocessor"></span><span class="preprocessor">#define MAX_TRIES 16</span>
<a name="l00045"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#b60883baeb411c29907975faef74cb59">00045</a> <span class="preprocessor"></span><span class="preprocessor">#define DOWNHILL_THRESH 0.05</span>
<a name="l00046"></a>00046 <span class="preprocessor"></span>
<a name="l00052"></a><a class="code" href="class_temp.html">00052</a> <span class="keyword">class </span><a class="code" href="class_temp.html">Temp</a> : <span class="keyword">public</span> <a class="code" href="classlibpg_1_1_softmax_policy.html">SoftmaxPolicy</a>::<a class="code" href="classlibpg_1_1_softmax_policy_1_1_temperature.html#5dfa54b70da631c6e5866811e8e8845f">Temperature</a> {
<a name="l00053"></a>00053 
<a name="l00054"></a>00054 <span class="keyword">public</span>:
<a name="l00055"></a>00055 
<a name="l00056"></a><a class="code" href="class_temp.html#3cc625d67a057bcfc7f9a93d0fb153e7">00056</a> <a class="code" href="class_temp.html#3cc625d67a057bcfc7f9a93d0fb153e7">Temp</a>(<span class="keywordtype">double</span> K) {
<a name="l00057"></a>00057     this-&gt;K = K;
<a name="l00058"></a>00058 }
<a name="l00059"></a>00059 
<a name="l00065"></a><a class="code" href="class_temp.html#2abc0b10fea7564e85141119f9e4960f">00065</a> <span class="keywordtype">double</span> <a class="code" href="class_temp.html#2abc0b10fea7564e85141119f9e4960f">getValue</a>(<span class="keywordtype">int</span> steps) {
<a name="l00066"></a>00066     <span class="keywordflow">return</span> (<span class="keywordtype">double</span>) 1.0 / ((1.0 + K * (double)steps)*(1.0 + K * (double)steps));
<a name="l00067"></a>00067 }
<a name="l00068"></a>00068 
<a name="l00069"></a>00069 <span class="keyword">private</span>:
<a name="l00070"></a>00070 
<a name="l00071"></a>00071     <span class="keywordtype">double</span> K;
<a name="l00072"></a>00072 
<a name="l00073"></a>00073 };
<a name="l00074"></a>00074 
<a name="l00075"></a>00075 
<a name="l00076"></a><a class="code" href="class_epsilon_decay.html">00076</a> <span class="keyword">class </span><a class="code" href="class_epsilon_decay.html">EpsilonDecay</a> : <span class="keyword">public</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>::<a class="code" href="classlibpg_1_1e_greedy_policy_1_1_epsilon_function.html#4341282404ae394d2d5c4fa3fc23c533">EpsilonFunction</a> {
<a name="l00077"></a>00077     
<a name="l00078"></a>00078 <span class="keyword">private</span>:
<a name="l00079"></a>00079     <span class="keywordtype">double</span> K;
<a name="l00080"></a>00080     
<a name="l00081"></a>00081 <span class="keyword">public</span>:
<a name="l00082"></a>00082     
<a name="l00083"></a><a class="code" href="class_epsilon_decay.html#b8fdb0e1f83641adf62044169e869ff3">00083</a>     <a class="code" href="class_epsilon_decay.html#b8fdb0e1f83641adf62044169e869ff3">EpsilonDecay</a>(<span class="keywordtype">double</span> K) {
<a name="l00084"></a>00084         this-&gt;K=K;
<a name="l00085"></a>00085     }
<a name="l00086"></a>00086     
<a name="l00087"></a><a class="code" href="class_epsilon_decay.html#c30b4ea54df6dec9df988f1071f082bc">00087</a>     <span class="keywordtype">double</span> <a class="code" href="class_epsilon_decay.html#c30b4ea54df6dec9df988f1071f082bc">getValue</a>(<span class="keywordtype">int</span> steps) {
<a name="l00088"></a>00088         <span class="keywordflow">return</span> (<span class="keywordtype">double</span>) 1.0 / ((1.0 + K * (double)steps)*(1.0 + K * (double)steps));
<a name="l00089"></a>00089     }
<a name="l00090"></a>00090     
<a name="l00091"></a>00091 };
<a name="l00092"></a>00092 
<a name="l00093"></a>00093 
<a name="l00101"></a>00101 <span class="keyword">template</span> &lt;<span class="keyword">class</span> Controller&gt;
<a name="l00102"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#e19b0d7a1334bc363fd983ef1a7e7d3b">00102</a> <span class="keywordtype">void</span> <a class="code" href="_tao_project_2_three_state_test_8cc.html#e19b0d7a1334bc363fd983ef1a7e7d3b">ExploreeGreedyKnobs</a>(<span class="keywordtype">int</span> max_time, <span class="keywordtype">int</span> max_steps) {
<a name="l00103"></a>00103     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> nnDims(<a class="code" href="crf_8cc.html#42d8249c71df0cfa9839aad0e8f583d7">NN_LAYERS</a>);
<a name="l00104"></a>00104     nnDims[0] = <a class="code" href="_grid_sim_8cc.html#f80bc950ecebb77deb2747f9a787a95a">OBS_DIM</a>;
<a name="l00105"></a>00105     nnDims[1] = <a class="code" href="crf_8cc.html#4d21079c4be880d193a8b3b7df9c467b">APPROX_OUTPUTS</a>;
<a name="l00106"></a>00106 
<a name="l00107"></a>00107     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> squash(<a class="code" href="crf_8cc.html#42d8249c71df0cfa9839aad0e8f583d7">NN_LAYERS</a>); 
<a name="l00108"></a>00108     squash.clear();
<a name="l00109"></a>00109 
<a name="l00110"></a>00110     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> tuple(4);
<a name="l00111"></a>00111     tuple(0) = 0.0;
<a name="l00112"></a>00112 
<a name="l00113"></a>00113     <span class="comment">// Varies epsilon (21 different values):</span>
<a name="l00114"></a>00114     <span class="comment">//  for (double epsilon = 0.0 ; epsilon &lt;= 1.0 ; epsilon += 0.05) {</span>
<a name="l00115"></a>00115     <span class="keywordflow">for</span> (<span class="keywordtype">double</span> K = 1e-8 ; K &lt;= 1e-2 ; K *= 10) {
<a name="l00116"></a>00116         <a class="code" href="classlibpg_1_1_controller.html">Controller</a> *controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_controller.html">Controller</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00117"></a>00117                                                 (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_epsilon_decay.html">EpsilonDecay</a>(K)), <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00118"></a>00118         <span class="comment">// Varies step-size (6 different values):</span>
<a name="l00119"></a>00119         <span class="keywordflow">for</span> (<span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 1e-7; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> &lt;= 1e-2 ; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> *= 10)
<a name="l00120"></a>00120 
<a name="l00121"></a>00121             <span class="comment">// Varies lambda (10 different values):</span>
<a name="l00122"></a>00122             <span class="keywordflow">for</span> (<span class="keywordtype">double</span> discount = 0.0; discount &lt;= 0.9 ; discount += 0.1) {
<a name="l00123"></a>00123                 <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a> *agent = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a>);
<a name="l00124"></a>00124                 agent-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00125"></a>00125                 <span class="keywordtype">double</span> reward = agent-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, max_time, max_steps);
<a name="l00126"></a>00126                 cout &lt;&lt; <span class="stringliteral">"Attempt: K = "</span> &lt;&lt; K &lt;&lt; <span class="stringliteral">", step_size = "</span> &lt;&lt; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> &lt;&lt; <span class="stringliteral">", labda = "</span>
<a name="l00127"></a>00127                      &lt;&lt; discount &lt;&lt; <span class="stringliteral">", reward = "</span> &lt;&lt; reward &lt;&lt; endl;
<a name="l00128"></a>00128                 <span class="keywordflow">if</span> (reward &gt; tuple(0)) {
<a name="l00129"></a>00129                     tuple(0) = reward;
<a name="l00130"></a>00130                     tuple(1) = K;
<a name="l00131"></a>00131                     tuple(2) = <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a>;
<a name="l00132"></a>00132                     tuple(3) = discount;
<a name="l00133"></a>00133                 }
<a name="l00134"></a>00134 
<a name="l00135"></a>00135                 <span class="keyword">delete</span> agent;
<a name="l00136"></a>00136             }
<a name="l00137"></a>00137 
<a name="l00138"></a>00138             <span class="keyword">delete</span> controller;
<a name="l00139"></a>00139     }
<a name="l00140"></a>00140 
<a name="l00141"></a>00141     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"The best average reward was found with:"</span> &lt;&lt; endl;
<a name="l00142"></a>00142     cout &lt;&lt; <span class="stringliteral">"reward = "</span> &lt;&lt; tuple(0) &lt;&lt; <span class="stringliteral">", K = "</span> &lt;&lt; tuple(1) &lt;&lt; <span class="stringliteral">", step_size = "</span> &lt;&lt; tuple(2) &lt;&lt; <span class="stringliteral">", discount = "</span> &lt;&lt; tuple(3) &lt;&lt; endl;
<a name="l00143"></a>00143 }
<a name="l00144"></a>00144 
<a name="l00152"></a>00152 <span class="keyword">template</span> &lt;<span class="keyword">class</span> Controller&gt;
<a name="l00153"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#2f886fdf6b744287743a329f4a2e6595">00153</a> <span class="keywordtype">void</span> <a class="code" href="_tao_project_2_three_state_test_8cc.html#2f886fdf6b744287743a329f4a2e6595">ExploreSoftmaxKnobs</a>(<span class="keywordtype">int</span> max_time, <span class="keywordtype">int</span> max_steps) {
<a name="l00154"></a>00154     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> nnDims(<a class="code" href="crf_8cc.html#42d8249c71df0cfa9839aad0e8f583d7">NN_LAYERS</a>);
<a name="l00155"></a>00155     nnDims[0] = <a class="code" href="_grid_sim_8cc.html#f80bc950ecebb77deb2747f9a787a95a">OBS_DIM</a>;
<a name="l00156"></a>00156     nnDims[1] = <a class="code" href="crf_8cc.html#4d21079c4be880d193a8b3b7df9c467b">APPROX_OUTPUTS</a>;
<a name="l00157"></a>00157 
<a name="l00158"></a>00158     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> squash(<a class="code" href="crf_8cc.html#42d8249c71df0cfa9839aad0e8f583d7">NN_LAYERS</a>); 
<a name="l00159"></a>00159     squash.clear();
<a name="l00160"></a>00160 
<a name="l00161"></a>00161     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> tuple(4);
<a name="l00162"></a>00162     tuple(0) = 0.0;
<a name="l00163"></a>00163 
<a name="l00164"></a>00164     <span class="comment">// Varies K (7 different values):</span>
<a name="l00165"></a>00165     <span class="keywordflow">for</span> (<span class="keywordtype">double</span> K = 1e-8 ; K &lt;= 1e-2 ; K *= 10) {
<a name="l00166"></a>00166         <a class="code" href="classlibpg_1_1_controller.html">Controller</a> *controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_controller.html">Controller</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00167"></a>00167                                                 (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_softmax_policy.html">SoftmaxPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_temp.html">Temp</a>(K)), <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00168"></a>00168 
<a name="l00169"></a>00169         <span class="comment">// Varies step-size (6 different values):</span>
<a name="l00170"></a>00170         <span class="keywordflow">for</span> (<span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 1e-7; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> &lt;= 1e-2 ; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> *= 10)
<a name="l00171"></a>00171 
<a name="l00172"></a>00172             <span class="comment">// Varies lambda (9 different values):</span>
<a name="l00173"></a>00173             <span class="keywordflow">for</span> (<span class="keywordtype">double</span> discount = 0.0; discount &lt;= 0.8 ; discount += 0.1) {
<a name="l00174"></a>00174                 <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a> *agent = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a>);
<a name="l00175"></a>00175                 agent-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00176"></a>00176                 <span class="keywordtype">double</span> reward = agent-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, max_time, max_steps);
<a name="l00177"></a>00177                 cout &lt;&lt; <span class="stringliteral">"Attempt: K = "</span> &lt;&lt; K &lt;&lt; <span class="stringliteral">", step_size = "</span> &lt;&lt; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> &lt;&lt; <span class="stringliteral">", labda = "</span>
<a name="l00178"></a>00178                      &lt;&lt; discount &lt;&lt; <span class="stringliteral">", reward = "</span> &lt;&lt; reward &lt;&lt; endl;
<a name="l00179"></a>00179                 <span class="keywordflow">if</span> (reward &gt; tuple(0)) {
<a name="l00180"></a>00180                     tuple(0) = reward;
<a name="l00181"></a>00181                     tuple(1) = K;
<a name="l00182"></a>00182                     tuple(2) = <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a>;
<a name="l00183"></a>00183                     tuple(3) = discount;
<a name="l00184"></a>00184                 }
<a name="l00185"></a>00185 
<a name="l00186"></a>00186                 <span class="keyword">delete</span> agent;
<a name="l00187"></a>00187             }
<a name="l00188"></a>00188 
<a name="l00189"></a>00189             <span class="keyword">delete</span> controller;
<a name="l00190"></a>00190     }
<a name="l00191"></a>00191 
<a name="l00192"></a>00192     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"The best average reward was found with:"</span> &lt;&lt; endl;
<a name="l00193"></a>00193     cout &lt;&lt; <span class="stringliteral">"reward = "</span> &lt;&lt; tuple(0) &lt;&lt; <span class="stringliteral">", K = "</span> &lt;&lt; tuple(1) &lt;&lt; <span class="stringliteral">", step_size = "</span> &lt;&lt; tuple(2) &lt;&lt; <span class="stringliteral">", discount = "</span> &lt;&lt; tuple(3) &lt;&lt; endl;
<a name="l00194"></a>00194 }
<a name="l00195"></a>00195 
<a name="l00203"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#46dfdc187cd04de6399800376f2a794e">00203</a> <span class="keywordtype">void</span> <a class="code" href="_tao_project_2_three_state_test_8cc.html#46dfdc187cd04de6399800376f2a794e">ExploreBinaryControllerKnobs</a>(<span class="keywordtype">int</span> max_time, <span class="keywordtype">int</span> max_steps) {
<a name="l00204"></a>00204     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> nnDims(<a class="code" href="crf_8cc.html#42d8249c71df0cfa9839aad0e8f583d7">NN_LAYERS</a>);
<a name="l00205"></a>00205     nnDims[0] = <a class="code" href="_grid_sim_8cc.html#f80bc950ecebb77deb2747f9a787a95a">OBS_DIM</a>;
<a name="l00206"></a>00206     nnDims[1] = <a class="code" href="crf_8cc.html#4d21079c4be880d193a8b3b7df9c467b">APPROX_OUTPUTS</a>;
<a name="l00207"></a>00207 
<a name="l00208"></a>00208     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> squash(<a class="code" href="crf_8cc.html#42d8249c71df0cfa9839aad0e8f583d7">NN_LAYERS</a>); 
<a name="l00209"></a>00209     squash.clear();
<a name="l00210"></a>00210 
<a name="l00211"></a>00211     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> tuple(3);
<a name="l00212"></a>00212     tuple(0) = 0.0;
<a name="l00213"></a>00213 
<a name="l00214"></a>00214     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash));
<a name="l00215"></a>00215 
<a name="l00216"></a>00216     <span class="comment">// Varies step-size (6 different values):</span>
<a name="l00217"></a>00217     <span class="keywordflow">for</span> (<span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 1e-7; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> &lt;= 1e-2 ; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> *= 10)
<a name="l00218"></a>00218 
<a name="l00219"></a>00219         <span class="comment">// Varies lambda (9 different values):</span>
<a name="l00220"></a>00220         <span class="keywordflow">for</span> (<span class="keywordtype">double</span> discount = 0.0; discount &lt;= 0.8 ; discount += 0.1) {
<a name="l00221"></a>00221             <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a> *agent = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a>);
<a name="l00222"></a>00222             agent-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00223"></a>00223             <span class="keywordtype">double</span> reward = agent-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, max_time, max_steps);
<a name="l00224"></a>00224             cout &lt;&lt; <span class="stringliteral">"Attempt: step_size = "</span> &lt;&lt; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> &lt;&lt; <span class="stringliteral">", labda = "</span>
<a name="l00225"></a>00225                  &lt;&lt; discount &lt;&lt; <span class="stringliteral">", reward = "</span> &lt;&lt; reward &lt;&lt; endl;
<a name="l00226"></a>00226             <span class="keywordflow">if</span> (reward &gt; tuple(0)) {
<a name="l00227"></a>00227                 tuple(0) = reward;
<a name="l00228"></a>00228                 tuple(1) = <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a>;
<a name="l00229"></a>00229                 tuple(2) = discount;
<a name="l00230"></a>00230             }
<a name="l00231"></a>00231 
<a name="l00232"></a>00232             <span class="keyword">delete</span> agent;
<a name="l00233"></a>00233         }
<a name="l00234"></a>00234 
<a name="l00235"></a>00235     <span class="keyword">delete</span> controller;
<a name="l00236"></a>00236 
<a name="l00237"></a>00237     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"The best average reward was found with:"</span> &lt;&lt; endl;
<a name="l00238"></a>00238     cout &lt;&lt; <span class="stringliteral">"reward = "</span> &lt;&lt; tuple(0) &lt;&lt; <span class="stringliteral">", step_size = "</span> &lt;&lt; tuple(1) &lt;&lt; <span class="stringliteral">", discount = "</span> &lt;&lt; tuple(2) &lt;&lt; endl;
<a name="l00239"></a>00239 }
<a name="l00240"></a>00240  
<a name="l00248"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#3561cff7c5cd3c1f98d3017a24dde9f5">00248</a> <span class="keywordtype">void</span> <a class="code" href="_tao_project_2_three_state_test_8cc.html#3561cff7c5cd3c1f98d3017a24dde9f5">ExploreFactoredBinaryControllersKnobs</a>(<span class="keywordtype">int</span> max_time, <span class="keywordtype">int</span> max_steps) {
<a name="l00249"></a>00249     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> nnDims(<a class="code" href="crf_8cc.html#42d8249c71df0cfa9839aad0e8f583d7">NN_LAYERS</a>);
<a name="l00250"></a>00250     nnDims[0] = <a class="code" href="_grid_sim_8cc.html#f80bc950ecebb77deb2747f9a787a95a">OBS_DIM</a>;
<a name="l00251"></a>00251     nnDims[1] = <a class="code" href="crf_8cc.html#4d21079c4be880d193a8b3b7df9c467b">APPROX_OUTPUTS</a>;
<a name="l00252"></a>00252 
<a name="l00253"></a>00253     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> squash(<a class="code" href="crf_8cc.html#42d8249c71df0cfa9839aad0e8f583d7">NN_LAYERS</a>); 
<a name="l00254"></a>00254     squash.clear();
<a name="l00255"></a>00255 
<a name="l00256"></a>00256     <a class="code" href="_basic_8h.html#a4cc4d8d5e5c7eb8bf12a00d290e936d">Vector</a> tuple(3);
<a name="l00257"></a>00257     tuple(0) = 0.0;
<a name="l00258"></a>00258 
<a name="l00259"></a>00259     FactoredController::Controllers controllers;
<a name="l00260"></a>00260     controllers.push_back(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash)));
<a name="l00261"></a>00261     controllers.push_back(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash)));
<a name="l00262"></a>00262     controllers.push_back(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash)));
<a name="l00263"></a>00263 
<a name="l00264"></a>00264     <span class="comment">// Varies step-size (6 different values):</span>
<a name="l00265"></a>00265     <span class="keywordflow">for</span> (<span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 1e-7; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> &lt;= 1e-2 ; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> *= 10)
<a name="l00266"></a>00266 
<a name="l00267"></a>00267         <span class="comment">// Varies lambda (9 different values):</span>
<a name="l00268"></a>00268         <span class="keywordflow">for</span> (<span class="keywordtype">double</span> discount = 0.0; discount &lt;= 0.8 ; discount += 0.1) {
<a name="l00269"></a>00269             <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a> *agent = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_factored_controller.html">FactoredController</a>(controllers, <span class="keyword">false</span>, <span class="keyword">false</span>), <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a>);
<a name="l00270"></a>00270             agent-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00271"></a>00271             <span class="keywordtype">double</span> reward = agent-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, max_time, max_steps);
<a name="l00272"></a>00272             cout &lt;&lt; <span class="stringliteral">"Attempt: step_size = "</span> &lt;&lt; <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> &lt;&lt; <span class="stringliteral">", labda = "</span>
<a name="l00273"></a>00273                  &lt;&lt; discount &lt;&lt; <span class="stringliteral">", reward = "</span> &lt;&lt; reward &lt;&lt; endl;
<a name="l00274"></a>00274             <span class="keywordflow">if</span> (reward &gt; tuple(0)) {
<a name="l00275"></a>00275                 tuple(0) = reward;
<a name="l00276"></a>00276                 tuple(1) = <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a>;
<a name="l00277"></a>00277                 tuple(2) = discount;
<a name="l00278"></a>00278             }
<a name="l00279"></a>00279 
<a name="l00280"></a>00280             <span class="keyword">delete</span> agent;
<a name="l00281"></a>00281         }
<a name="l00282"></a>00282 
<a name="l00283"></a>00283     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"The best average reward was found with:"</span> &lt;&lt; endl;
<a name="l00284"></a>00284     cout &lt;&lt; <span class="stringliteral">"reward = "</span> &lt;&lt; tuple(0) &lt;&lt; <span class="stringliteral">", step_size = "</span> &lt;&lt; tuple(1) &lt;&lt; <span class="stringliteral">", discount = "</span> &lt;&lt; tuple(2) &lt;&lt; endl;
<a name="l00285"></a>00285 }
<a name="l00286"></a>00286 
<a name="l00287"></a>00287 
<a name="l00288"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">00288</a> <span class="preprocessor">#define commonInit() \</span>
<a name="l00289"></a>00289 <span class="preprocessor">    Vector nnDims(NN_LAYERS); \</span>
<a name="l00290"></a>00290 <span class="preprocessor">    nnDims[0] = OBS_DIM; \</span>
<a name="l00291"></a>00291 <span class="preprocessor">    nnDims[1] = APPROX_OUTPUTS; \</span>
<a name="l00292"></a>00292 <span class="preprocessor">    Vector squash(NN_LAYERS); \</span>
<a name="l00293"></a>00293 <span class="preprocessor">    squash.clear();</span>
<a name="l00294"></a>00294 <span class="preprocessor"></span>
<a name="l00295"></a>00295 
<a name="l00301"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#becc2f63e247b6f767ae91ff1abc3d76">00301</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#becc2f63e247b6f767ae91ff1abc3d76">SARSA_NeuralNet_Softmax_Decaying</a>() {
<a name="l00302"></a>00302     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00303"></a>00303 
<a name="l00304"></a>00304 
<a name="l00305"></a>00305     <span class="comment">// With eligibility traces</span>
<a name="l00306"></a>00306     <span class="comment">// Expected reward ~ 2.58</span>
<a name="l00307"></a>00307     <span class="keywordtype">double</span> discount =  0.4;
<a name="l00308"></a>00308     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00309"></a>00309     <span class="keywordtype">double</span> kapa =      1e-05;
<a name="l00310"></a>00310 
<a name="l00311"></a>00311     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running SARSA with NeuralNet approximator and Softmax policy with decaying temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00312"></a>00312  
<a name="l00313"></a>00313     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_s_a_r_s_a_controller.html">SARSAController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00314"></a>00314                                                  <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_softmax_policy.html">SoftmaxPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_temp.html">Temp</a>(kapa)),
<a name="l00315"></a>00315                                                  <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00316"></a>00316 
<a name="l00317"></a>00317     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00318"></a>00318 
<a name="l00319"></a>00319     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00320"></a>00320 
<a name="l00321"></a>00321     <span class="keywordflow">return</span> learner;
<a name="l00322"></a>00322 }
<a name="l00323"></a>00323 
<a name="l00324"></a>00324 
<a name="l00325"></a>00325 
<a name="l00331"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#7bb326eae67fcfb4c2a76ab6e8c3674f">00331</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#7bb326eae67fcfb4c2a76ab6e8c3674f">LSPI_NeuralNet_Softmax_Decaying</a>() {
<a name="l00332"></a>00332     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00333"></a>00333 
<a name="l00334"></a>00334     <span class="comment">// With eligibility traces</span>
<a name="l00335"></a>00335     <span class="comment">// Expected reward ~ 2.58</span>
<a name="l00336"></a>00336     <span class="keywordtype">double</span> discount =  0.0; <span class="comment">// Should be 0.0 for true LSPI</span>
<a name="l00337"></a>00337     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.0; <span class="comment">// Ignored</span>
<a name="l00338"></a>00338     <span class="keywordtype">double</span> kapa =      1e-05;
<a name="l00339"></a>00339 
<a name="l00340"></a>00340     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running LSPI with softmax policy with decaying temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00341"></a>00341  
<a name="l00342"></a>00342 
<a name="l00343"></a>00343     <span class="comment">// Note that construction of the basis vectors for LSPI implicity produces an OBS_DIM*APPROX_OUTPUTS</span>
<a name="l00344"></a>00344     <span class="comment">// vector, with all 0's except it has a copy of the observation vector at the relevant action</span>
<a name="l00345"></a>00345     <span class="comment">// for whatever action we are approximating the value of.</span>
<a name="l00346"></a>00346     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> LSPIController(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(<a class="code" href="_grid_sim_8cc.html#f80bc950ecebb77deb2747f9a787a95a">OBS_DIM</a>, <a class="code" href="crf_8cc.html#4d21079c4be880d193a8b3b7df9c467b">APPROX_OUTPUTS</a>),
<a name="l00347"></a>00347                                                 (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_softmax_policy.html">SoftmaxPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_temp.html">Temp</a>(kapa)),
<a name="l00348"></a>00348                                                 <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00349"></a>00349 
<a name="l00350"></a>00350     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00351"></a>00351 
<a name="l00352"></a>00352     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00353"></a>00353 
<a name="l00354"></a>00354     <span class="keywordflow">return</span> learner;
<a name="l00355"></a>00355 }
<a name="l00356"></a>00356 
<a name="l00357"></a>00357 <span class="comment">/* Tao add */</span>
<a name="l00358"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#9e2b6a85019de2bbf52a07475f7f213d">00358</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#9e2b6a85019de2bbf52a07475f7f213d">LSPI_NeuralNet_Uniform_Random</a>() {
<a name="l00359"></a>00359     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00360"></a>00360 
<a name="l00361"></a>00361     <span class="comment">// With eligibility traces</span>
<a name="l00362"></a>00362     <span class="comment">// Expected reward ~ 2.58</span>
<a name="l00363"></a>00363     <span class="keywordtype">double</span> discount =  0.0; <span class="comment">// Should be 0.0 for true LSPI</span>
<a name="l00364"></a>00364     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.0; <span class="comment">// Ignored</span>
<a name="l00365"></a>00365         <span class="keywordtype">double</span> epsilon =   1.0;
<a name="l00366"></a>00366   
<a name="l00367"></a>00367     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running LSPI with NeuralNet approximator and random policy with constant epsilon = 1:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00368"></a>00368 
<a name="l00369"></a>00369     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller= <span class="keyword">new</span> LSPIController(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00370"></a>00370                                                 (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(epsilon),
<a name="l00371"></a>00371                                                 <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00372"></a>00372 
<a name="l00373"></a>00373     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00374"></a>00374 
<a name="l00375"></a>00375     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00376"></a>00376 
<a name="l00377"></a>00377     <span class="keywordflow">return</span> learner; 
<a name="l00378"></a>00378 }
<a name="l00379"></a>00379 
<a name="l00380"></a>00380 
<a name="l00386"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#9771ff6ecc40282478201ec8b1f068aa">00386</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#9771ff6ecc40282478201ec8b1f068aa">SARSA_NeuralNet_eGreedy_Constant</a>() {
<a name="l00387"></a>00387     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00388"></a>00388 
<a name="l00389"></a>00389     <span class="comment">// Expected reward ~ 2.5</span>
<a name="l00390"></a>00390     <span class="keywordtype">double</span> discount =  0.5;
<a name="l00391"></a>00391     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00392"></a>00392     <span class="keywordtype">double</span> epsilon =   0.01;
<a name="l00393"></a>00393   
<a name="l00394"></a>00394     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running SARSA with NeuralNet approximator and e-Greedy policy with constant epsilon:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00395"></a>00395 
<a name="l00396"></a>00396     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller= <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_s_a_r_s_a_controller.html">SARSAController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00397"></a>00397                                                 (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(epsilon),
<a name="l00398"></a>00398                                                 <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00399"></a>00399 
<a name="l00400"></a>00400     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00401"></a>00401 
<a name="l00402"></a>00402     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00403"></a>00403 
<a name="l00404"></a>00404     <span class="keywordflow">return</span> learner;
<a name="l00405"></a>00405 }
<a name="l00406"></a>00406 
<a name="l00412"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#431d4c751d9c2039659207c24eb8812e">00412</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#431d4c751d9c2039659207c24eb8812e">SARSA_NeuralNet_eGreedy_Decaying</a>() {
<a name="l00413"></a>00413     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00414"></a>00414 
<a name="l00415"></a>00415     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00416"></a>00416     <span class="keywordtype">double</span> discount =  0.7;
<a name="l00417"></a>00417     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00418"></a>00418     <span class="keywordtype">double</span> kapa =      0.001;
<a name="l00419"></a>00419   
<a name="l00420"></a>00420     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running SARSA with NeuralNet approximator and e-Greedy policy with decaying epsilon:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00421"></a>00421 
<a name="l00422"></a>00422     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_s_a_r_s_a_controller.html">SARSAController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00423"></a>00423                                                  (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_epsilon_decay.html">EpsilonDecay</a>(kapa)),
<a name="l00424"></a>00424                                                  <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00425"></a>00425 
<a name="l00426"></a>00426     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00427"></a>00427 
<a name="l00428"></a>00428     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00429"></a>00429 
<a name="l00430"></a>00430     <span class="keywordflow">return</span> learner;
<a name="l00431"></a>00431 }
<a name="l00432"></a>00432 
<a name="l00438"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#477f5c611b58b35c1ad49d4a77652ca6">00438</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#477f5c611b58b35c1ad49d4a77652ca6">QLearning_NeuralNet_Softmax_Decaying</a>() {
<a name="l00439"></a>00439     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00440"></a>00440 
<a name="l00441"></a>00441     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00442"></a>00442     <span class="keywordtype">double</span> discount =  0.4;
<a name="l00443"></a>00443     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00444"></a>00444     <span class="keywordtype">double</span> kapa =      1e-05;
<a name="l00445"></a>00445   
<a name="l00446"></a>00446     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running QLearning with NeuralNet approximator and Softmax policy with decaying temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00447"></a>00447 
<a name="l00448"></a>00448     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_q_learning_controller.html">QLearningController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00449"></a>00449                                                      (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_softmax_policy.html">SoftmaxPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_temp.html">Temp</a>(kapa)),
<a name="l00450"></a>00450                                                      <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00451"></a>00451 
<a name="l00452"></a>00452     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00453"></a>00453 
<a name="l00454"></a>00454     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00455"></a>00455 
<a name="l00456"></a>00456     <span class="keywordflow">return</span> learner;
<a name="l00457"></a>00457 }
<a name="l00458"></a>00458 
<a name="l00464"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#a216cc990b9186296e1a5bb256e17b9f">00464</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#a216cc990b9186296e1a5bb256e17b9f">QLearning_NeuralNet_eGreedy_Constant</a>() {
<a name="l00465"></a>00465     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00466"></a>00466 
<a name="l00467"></a>00467     <span class="comment">// Expected reward ~ 2.5</span>
<a name="l00468"></a>00468     <span class="keywordtype">double</span> discount =  0.5;
<a name="l00469"></a>00469     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00470"></a>00470     <span class="keywordtype">double</span> epsilon =   0.01;
<a name="l00471"></a>00471   
<a name="l00472"></a>00472     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running QLearning with NeuralNet approximator and e-Greedy policy with constant temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00473"></a>00473 
<a name="l00474"></a>00474     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_q_learning_controller.html">QLearningController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00475"></a>00475                                                      (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(epsilon),
<a name="l00476"></a>00476                                                      <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00477"></a>00477 
<a name="l00478"></a>00478     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00479"></a>00479 
<a name="l00480"></a>00480     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00481"></a>00481 
<a name="l00482"></a>00482     <span class="keywordflow">return</span> learner;
<a name="l00483"></a>00483 }
<a name="l00484"></a>00484 
<a name="l00490"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#ac281e0f52bdd877cd62a331747543e3">00490</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#ac281e0f52bdd877cd62a331747543e3">QLearning_NeuralNet_eGreedy_Decaying</a>() {
<a name="l00491"></a>00491     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00492"></a>00492 
<a name="l00493"></a>00493     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00494"></a>00494     <span class="keywordtype">double</span> discount =  0.4;
<a name="l00495"></a>00495     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00496"></a>00496     <span class="keywordtype">double</span> kapa =      0.001;
<a name="l00497"></a>00497   
<a name="l00498"></a>00498     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running QLearning with NeuralNet approximator and e-Greedy policy with decaying temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00499"></a>00499 
<a name="l00500"></a>00500     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_q_learning_controller.html">QLearningController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00501"></a>00501                                                      (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_epsilon_decay.html">EpsilonDecay</a>(kapa)),
<a name="l00502"></a>00502                                                      <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00503"></a>00503 
<a name="l00504"></a>00504     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00505"></a>00505 
<a name="l00506"></a>00506     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00507"></a>00507 
<a name="l00508"></a>00508     <span class="keywordflow">return</span> learner;
<a name="l00509"></a>00509 }
<a name="l00510"></a>00510 
<a name="l00515"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#78ae3e8aebf678403bb6637be9e1e624">00515</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#78ae3e8aebf678403bb6637be9e1e624">Basic_NeuralNet</a>() {
<a name="l00516"></a>00516     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00517"></a>00517 
<a name="l00518"></a>00518     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00519"></a>00519     <span class="keywordtype">double</span> discount =  0.6;
<a name="l00520"></a>00520     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.000001;
<a name="l00521"></a>00521   
<a name="l00522"></a>00522     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running Basic controller with NeuralNet approximator:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00523"></a>00523 
<a name="l00524"></a>00524     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_basic_controller.html">BasicController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash));
<a name="l00525"></a>00525 
<a name="l00526"></a>00526     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00527"></a>00527 
<a name="l00528"></a>00528     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">false</span>);
<a name="l00529"></a>00529 
<a name="l00530"></a>00530     <span class="keywordflow">return</span> learner;
<a name="l00531"></a>00531 }
<a name="l00532"></a>00532 
<a name="l00537"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#2d625379d853bfd2ce727bb562cea5e1">00537</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#2d625379d853bfd2ce727bb562cea5e1">NACTransform_Binary_NeuralNet</a>() {
<a name="l00538"></a>00538     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00539"></a>00539 
<a name="l00540"></a>00540     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00541"></a>00541     <span class="keywordtype">double</span> discount =  0.4;
<a name="l00542"></a>00542     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00543"></a>00543   
<a name="l00544"></a>00544     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running Binary controller with NeuralNet approximator:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00545"></a>00545 
<a name="l00546"></a>00546     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller= <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_n_a_c_transform.html">NACTransform</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net_batch.html">NeuralNetBatch</a>(nnDims, squash)), <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00547"></a>00547 
<a name="l00548"></a>00548     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00549"></a>00549 
<a name="l00550"></a>00550     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00551"></a>00551 
<a name="l00552"></a>00552     <span class="keywordflow">return</span> learner;
<a name="l00553"></a>00553 }
<a name="l00554"></a>00554 
<a name="l00559"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#6f03e304964440ee13b681fadf5fed66">00559</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#6f03e304964440ee13b681fadf5fed66">OLBFGS_NeuralNet</a>() {
<a name="l00560"></a>00560     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00561"></a>00561 
<a name="l00562"></a>00562     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00563"></a>00563     <span class="keywordtype">double</span> discount =  0.6;
<a name="l00564"></a>00564     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.1 ;
<a name="l00565"></a>00565     <span class="keywordtype">int</span> memory=3 ; <span class="comment">// [daa] I have no idea about what this should be</span>
<a name="l00566"></a>00566   
<a name="l00567"></a>00567     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running olBFGS with NeuralNet approximator:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00568"></a>00568 
<a name="l00569"></a>00569     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller= <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_b_f_g_s.html">OLBFGS</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_basic_controller.html">BasicController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net_batch.html">NeuralNetBatch</a>(nnDims, squash)), memory);
<a name="l00570"></a>00570 
<a name="l00571"></a>00571     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00572"></a>00572 
<a name="l00573"></a>00573     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">false</span>);
<a name="l00574"></a>00574 
<a name="l00575"></a>00575     <span class="keywordflow">return</span> learner;
<a name="l00576"></a>00576 }
<a name="l00577"></a>00577 
<a name="l00582"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#8476e95db07392daa62c2853e60e71a3">00582</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#8476e95db07392daa62c2853e60e71a3">Factored_Binary_NeuralNet</a>() {
<a name="l00583"></a>00583     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00584"></a>00584 
<a name="l00585"></a>00585     <span class="comment">// Expected reward ~ 2.5</span>
<a name="l00586"></a>00586     <span class="keywordtype">double</span> discount =  0.8;
<a name="l00587"></a>00587     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00588"></a>00588   
<a name="l00589"></a>00589     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running Binary controller with NeuralNet approximator:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00590"></a>00590 
<a name="l00591"></a>00591     FactoredController::Controllers controllers;
<a name="l00592"></a>00592     controllers.push_back(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash)));
<a name="l00593"></a>00593     controllers.push_back(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash)));
<a name="l00594"></a>00594     controllers.push_back(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash)));
<a name="l00595"></a>00595 
<a name="l00596"></a>00596     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_factored_controller.html">FactoredController</a>(controllers, <span class="keyword">false</span>, <span class="keyword">false</span>), <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), discount, step_size);
<a name="l00597"></a>00597 
<a name="l00598"></a>00598     learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#1cc00977560c6bfc96cc9c3e272307bb">setUseAutoBaseline</a>(<span class="keyword">true</span>);
<a name="l00599"></a>00599 
<a name="l00600"></a>00600     <span class="keywordflow">return</span> learner;
<a name="l00601"></a>00601 }
<a name="l00602"></a>00602 
<a name="l00603"></a><a class="code" href="_tao_project_2_three_state_test_8cc.html#3c04138a5bfe5d72780bb7e82a18e627">00603</a> <span class="keywordtype">int</span> <a class="code" href="_cassandra_test_8cc.html#3c04138a5bfe5d72780bb7e82a18e627">main</a>(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>** argv) {
<a name="l00604"></a>00604 
<a name="l00605"></a>00605     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = NULL;
<a name="l00606"></a>00606     time_t startTime = time(NULL);
<a name="l00607"></a>00607  
<a name="l00608"></a>00608 
<a name="l00609"></a>00609     <span class="keywordflow">if</span> (argc &gt; 1) {
<a name="l00610"></a>00610 
<a name="l00611"></a>00611         <span class="keywordflow">switch</span> (atoi(argv[1])) {
<a name="l00612"></a>00612 
<a name="l00613"></a>00613             <span class="keywordflow">case</span> 1:
<a name="l00614"></a>00614                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#becc2f63e247b6f767ae91ff1abc3d76">SARSA_NeuralNet_Softmax_Decaying</a>();
<a name="l00615"></a>00615                 <span class="keywordflow">break</span>;
<a name="l00616"></a>00616 
<a name="l00617"></a>00617             <span class="keywordflow">case</span> 2:
<a name="l00618"></a>00618                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#9771ff6ecc40282478201ec8b1f068aa">SARSA_NeuralNet_eGreedy_Constant</a>();
<a name="l00619"></a>00619                 <span class="keywordflow">break</span>;
<a name="l00620"></a>00620 
<a name="l00621"></a>00621             <span class="keywordflow">case</span> 3:
<a name="l00622"></a>00622                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#431d4c751d9c2039659207c24eb8812e">SARSA_NeuralNet_eGreedy_Decaying</a>();
<a name="l00623"></a>00623                 <span class="keywordflow">break</span>;
<a name="l00624"></a>00624 
<a name="l00625"></a>00625             <span class="keywordflow">case</span> 4:
<a name="l00626"></a>00626                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#477f5c611b58b35c1ad49d4a77652ca6">QLearning_NeuralNet_Softmax_Decaying</a>();
<a name="l00627"></a>00627                 <span class="keywordflow">break</span>;
<a name="l00628"></a>00628 
<a name="l00629"></a>00629             <span class="keywordflow">case</span> 5:
<a name="l00630"></a>00630                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#a216cc990b9186296e1a5bb256e17b9f">QLearning_NeuralNet_eGreedy_Constant</a>();
<a name="l00631"></a>00631                 <span class="keywordflow">break</span>;
<a name="l00632"></a>00632 
<a name="l00633"></a>00633             <span class="keywordflow">case</span> 6:
<a name="l00634"></a>00634                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#ac281e0f52bdd877cd62a331747543e3">QLearning_NeuralNet_eGreedy_Decaying</a>();
<a name="l00635"></a>00635                 <span class="keywordflow">break</span>;
<a name="l00636"></a>00636 
<a name="l00637"></a>00637             <span class="keywordflow">case</span> 7:
<a name="l00638"></a>00638                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#78ae3e8aebf678403bb6637be9e1e624">Basic_NeuralNet</a>();
<a name="l00639"></a>00639                 <span class="keywordflow">break</span>;
<a name="l00640"></a>00640 
<a name="l00641"></a>00641             <span class="keywordflow">case</span> 8:
<a name="l00642"></a>00642                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#2d625379d853bfd2ce727bb562cea5e1">NACTransform_Binary_NeuralNet</a>();
<a name="l00643"></a>00643                 <span class="keywordflow">break</span>;
<a name="l00644"></a>00644 
<a name="l00645"></a>00645             <span class="keywordflow">case</span> 9:
<a name="l00646"></a>00646                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#8476e95db07392daa62c2853e60e71a3">Factored_Binary_NeuralNet</a>();
<a name="l00647"></a>00647                 <span class="keywordflow">break</span>;
<a name="l00648"></a>00648 
<a name="l00649"></a>00649             <span class="keywordflow">case</span> 10:
<a name="l00650"></a>00650                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#7bb326eae67fcfb4c2a76ab6e8c3674f">LSPI_NeuralNet_Softmax_Decaying</a>();
<a name="l00651"></a>00651                 <span class="keywordflow">break</span>;
<a name="l00652"></a>00652             <span class="keywordflow">case</span> 11:
<a name="l00653"></a>00653                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#9e2b6a85019de2bbf52a07475f7f213d">LSPI_NeuralNet_Uniform_Random</a>();
<a name="l00654"></a>00654                 <span class="keywordflow">break</span>;
<a name="l00655"></a>00655             <span class="keywordflow">case</span> 12:
<a name="l00656"></a>00656                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#6f03e304964440ee13b681fadf5fed66">OLBFGS_NeuralNet</a>();
<a name="l00657"></a>00657                 <span class="keywordflow">break</span>;
<a name="l00658"></a>00658 
<a name="l00659"></a>00659             <span class="keywordflow">default</span>:
<a name="l00660"></a>00660                 cout &lt;&lt; <span class="stringliteral">"Invalid option!"</span> &lt;&lt; endl;
<a name="l00661"></a>00661                 <span class="keywordflow">break</span>;
<a name="l00662"></a>00662         }
<a name="l00663"></a>00663         
<a name="l00664"></a>00664         <span class="keywordflow">if</span> (learner != NULL) {
<a name="l00665"></a>00665             learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00666"></a>00666             <span class="keyword">delete</span> learner;  
<a name="l00667"></a>00667         }
<a name="l00668"></a>00668     }
<a name="l00669"></a>00669     <span class="keywordflow">else</span> {
<a name="l00670"></a>00670         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#becc2f63e247b6f767ae91ff1abc3d76">SARSA_NeuralNet_Softmax_Decaying</a>();
<a name="l00671"></a>00671         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00672"></a>00672         <span class="keyword">delete</span> learner;
<a name="l00673"></a>00673 
<a name="l00674"></a>00674         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#9771ff6ecc40282478201ec8b1f068aa">SARSA_NeuralNet_eGreedy_Constant</a>();
<a name="l00675"></a>00675         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00676"></a>00676         <span class="keyword">delete</span> learner;
<a name="l00677"></a>00677 
<a name="l00678"></a>00678         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#431d4c751d9c2039659207c24eb8812e">SARSA_NeuralNet_eGreedy_Decaying</a>();
<a name="l00679"></a>00679         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00680"></a>00680         <span class="keyword">delete</span> learner;
<a name="l00681"></a>00681 
<a name="l00682"></a>00682         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#477f5c611b58b35c1ad49d4a77652ca6">QLearning_NeuralNet_Softmax_Decaying</a>();
<a name="l00683"></a>00683         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00684"></a>00684         <span class="keyword">delete</span> learner;
<a name="l00685"></a>00685 
<a name="l00686"></a>00686         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#a216cc990b9186296e1a5bb256e17b9f">QLearning_NeuralNet_eGreedy_Constant</a>();
<a name="l00687"></a>00687         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00688"></a>00688         <span class="keyword">delete</span> learner;
<a name="l00689"></a>00689 
<a name="l00690"></a>00690         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#ac281e0f52bdd877cd62a331747543e3">QLearning_NeuralNet_eGreedy_Decaying</a>();
<a name="l00691"></a>00691         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00692"></a>00692         <span class="keyword">delete</span> learner;
<a name="l00693"></a>00693 
<a name="l00694"></a>00694 
<a name="l00695"></a>00695         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#7bb326eae67fcfb4c2a76ab6e8c3674f">LSPI_NeuralNet_Softmax_Decaying</a>();
<a name="l00696"></a>00696         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00697"></a>00697         <span class="keyword">delete</span> learner;
<a name="l00698"></a>00698         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#9e2b6a85019de2bbf52a07475f7f213d">LSPI_NeuralNet_Uniform_Random</a>();
<a name="l00699"></a>00699         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00700"></a>00700           <span class="keyword">delete</span> learner;
<a name="l00701"></a>00701 
<a name="l00702"></a>00702         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#78ae3e8aebf678403bb6637be9e1e624">Basic_NeuralNet</a>();
<a name="l00703"></a>00703         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00704"></a>00704         <span class="keyword">delete</span> learner;
<a name="l00705"></a>00705 
<a name="l00706"></a>00706         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#2d625379d853bfd2ce727bb562cea5e1">NACTransform_Binary_NeuralNet</a>();
<a name="l00707"></a>00707         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00708"></a>00708         <span class="keyword">delete</span> learner;
<a name="l00709"></a>00709         
<a name="l00710"></a>00710         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#8476e95db07392daa62c2853e60e71a3">Factored_Binary_NeuralNet</a>();
<a name="l00711"></a>00711         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00712"></a>00712         <span class="keyword">delete</span> learner;
<a name="l00713"></a>00713     }
<a name="l00714"></a>00714 
<a name="l00715"></a>00715     <span class="comment">// Below functions are meant to find the best parameters for each policy, algorithm and controller</span>
<a name="l00716"></a>00716 
<a name="l00717"></a>00717     <span class="comment">// ExploreSoftmaxKnobs&lt;SARSAController&gt;(MAX_TIME, MAX_STEPS);</span>
<a name="l00718"></a>00718     <span class="comment">// ExploreeGreedyKnobs&lt;SARSAController&gt;(MAX_TIME, MAX_STEPS);</span>
<a name="l00719"></a>00719     <span class="comment">// ExploreSoftmaxKnobs&lt;QLearningController&gt;(MAX_TIME, MAX_STEPS);</span>
<a name="l00720"></a>00720     <span class="comment">// ExploreeGreedyKnobs&lt;QLearningController&gt;(MAX_TIME, MAX_STEPS);</span>
<a name="l00721"></a>00721     <span class="comment">// ExploreBinaryControllerKnobs(MAX_TIME, MAX_STEPS);</span>
<a name="l00722"></a>00722     <span class="comment">// ExploreFactoredBinaryControllersKnobs(MAX_TIME, MAX_STEPS);</span>
<a name="l00723"></a>00723 
<a name="l00724"></a>00724     cout&lt;&lt;<span class="stringliteral">"Took "</span>&lt;&lt;time(NULL) - startTime&lt;&lt;<span class="stringliteral">" secs\n"</span>;
<a name="l00725"></a>00725 
<a name="l00726"></a>00726     <span class="keywordflow">return</span> 0;
<a name="l00727"></a>00727 }
</pre></div><hr size="1"><address style="text-align: right;"><small>Generated on Mon Sep 10 19:32:09 2007 for The PG Library by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.3 </small></address>
</body>
</html>
