<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
<title>The PG Library: /Users/daa/legacy/src/libpg/trunk/simulators/ThreeState/ThreeStateTest.cc Source File</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.3 -->
<div class="tabs">
  <ul>
    <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
    <li><a href="namespaces.html"><span>Namespaces</span></a></li>
    <li><a href="annotated.html"><span>Classes</span></a></li>
    <li class="current"><a href="files.html"><span>Files</span></a></li>
  </ul>
</div>
<h1>/Users/daa/legacy/src/libpg/trunk/simulators/ThreeState/ThreeStateTest.cc</h1><a href="_three_state_2_three_state_test_8cc.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00015"></a>00015 <span class="comment">// Main libpg header file for all libpg projects</span>
<a name="l00016"></a>00016 <span class="preprocessor">#include"<a class="code" href="_p_g_basics_8hh.html">PGBasics.hh</a>"</span>
<a name="l00017"></a>00017 
<a name="l00018"></a>00018 <span class="comment">// Your simulator class</span>
<a name="l00019"></a>00019 <span class="preprocessor">#include"<a class="code" href="_three_state_2_three_state_8hh.html">ThreeState.hh</a>"</span>
<a name="l00020"></a>00020 
<a name="l00021"></a>00021 <span class="comment">// Approximators</span>
<a name="l00022"></a>00022 <span class="preprocessor">#include"<a class="code" href="_lookup_table_8hh.html">LookupTable.hh</a>"</span>
<a name="l00023"></a>00023 <span class="preprocessor">#include"<a class="code" href="_lookup_table_batch_8hh.html">LookupTableBatch.hh</a>"</span> <span class="comment">// The batch versions are always safe to use over the non-batch</span>
<a name="l00024"></a>00024 <span class="preprocessor">#include"<a class="code" href="_neural_net_8hh.html">NeuralNet.hh</a>"</span>
<a name="l00025"></a>00025 <span class="preprocessor">#include"<a class="code" href="_neural_net_batch_8hh.html">NeuralNetBatch.hh</a>"</span>
<a name="l00026"></a>00026 <span class="preprocessor">#include"<a class="code" href="_n_a_c_transform_8hh.html">NACTransform.hh</a>"</span>
<a name="l00027"></a>00027 
<a name="l00028"></a>00028 <span class="comment">// Policies</span>
<a name="l00029"></a>00029 <span class="preprocessor">#include"<a class="code" href="_softmax_policy_8hh.html">SoftmaxPolicy.hh</a>"</span>
<a name="l00030"></a>00030 <span class="preprocessor">#include"<a class="code" href="e_greedy_policy_8hh.html">eGreedyPolicy.hh</a>"</span>
<a name="l00031"></a>00031 
<a name="l00032"></a>00032 <span class="comment">// Controllers</span>
<a name="l00033"></a>00033 <span class="comment">// Policy-gradient</span>
<a name="l00034"></a>00034 <span class="preprocessor">#include"<a class="code" href="_basic_controller_8hh.html">BasicController.hh</a>"</span>
<a name="l00035"></a>00035 <span class="preprocessor">#include"<a class="code" href="_binary_controller_8hh.html">BinaryController.hh</a>"</span>
<a name="l00036"></a>00036 <span class="comment">// Value based</span>
<a name="l00037"></a>00037 <span class="preprocessor">#include"<a class="code" href="_value_controller_8hh.html">ValueController.hh</a>"</span>
<a name="l00038"></a>00038 <span class="preprocessor">#include"<a class="code" href="_s_a_r_s_a_controller_8hh.html">SARSAController.hh</a>"</span>
<a name="l00039"></a>00039 <span class="preprocessor">#include"<a class="code" href="_q_learning_controller_8hh.html">QLearningController.hh</a>"</span>
<a name="l00040"></a>00040 <span class="preprocessor">#include"<a class="code" href="_factored_controller_8hh.html">FactoredController.hh</a>"</span>
<a name="l00041"></a>00041 <span class="preprocessor">#include"<a class="code" href="_l_s_t_d_q_controller_8hh.html">LSTDQController.hh</a>"</span>
<a name="l00042"></a>00042 
<a name="l00043"></a>00043 <span class="comment">// RL Algorithms</span>
<a name="l00044"></a>00044 <span class="preprocessor">#include"<a class="code" href="_o_l_pomdp_8hh.html">OLPomdp.hh</a>"</span>
<a name="l00045"></a>00045 <span class="preprocessor">#include"<a class="code" href="_g_pomdp_8hh.html">GPomdp.hh</a>"</span>
<a name="l00046"></a>00046 <span class="preprocessor">#include"<a class="code" href="_line_search_alg_8hh.html">LineSearchAlg.hh</a>"</span>
<a name="l00047"></a>00047 
<a name="l00048"></a>00048 <span class="keyword">using namespace </span>std;
<a name="l00049"></a>00049 <span class="keyword">using namespace </span>libpg;
<a name="l00050"></a>00050 
<a name="l00051"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#df579b0668a161d0ac966509f378a08d">00051</a> <span class="preprocessor">#define TD_DISCOUNT 0.6 // THe problem discount factor</span>
<a name="l00052"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#8c324bb806c51b79c1e30b5a3c80d3fe">00052</a> <span class="preprocessor"></span><span class="preprocessor">#define STEPS_PER_EPOCH 10000</span>
<a name="l00053"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#a0414caef00a64a51d4c6c0711d9e70a">00053</a> <span class="preprocessor"></span><span class="preprocessor">#define MAX_STEPS 10000000</span>
<a name="l00054"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#5320d4457a472d8888ec1905bc0e0a1c">00054</a> <span class="preprocessor"></span><span class="preprocessor">#define MAX_TIME 0</span>
<a name="l00055"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#773fba130cdfa9a0dba95ee0c76862c6">00055</a> <span class="preprocessor"></span><span class="preprocessor">#define TEST_RUNS 1</span>
<a name="l00056"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#42d8249c71df0cfa9839aad0e8f583d7">00056</a> <span class="preprocessor"></span><span class="preprocessor">#define NN_LAYERS 2 // 2 is linear, 3 or more for MLP</span>
<a name="l00057"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#ac4cbf64d7084205e04bc1b1569baf05">00057</a> <span class="preprocessor"></span><span class="preprocessor">#define PARAM_FILE "ThreeState.params"</span>
<a name="l00058"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#7bc1af4c33fb07fbd428f4359a9796b6">00058</a> <span class="preprocessor"></span><span class="preprocessor">#define MAX_RAND_PARAM 0.00</span>
<a name="l00059"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#4d21079c4be880d193a8b3b7df9c467b">00059</a> <span class="preprocessor"></span><span class="preprocessor">#define APPROX_OUTPUTS 2</span>
<a name="l00060"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#0eef36d721ed3a84124556f2929e81eb">00060</a> <span class="preprocessor"></span><span class="preprocessor">#define LINE_SEARCH_STEPS 20</span>
<a name="l00061"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#30c17564229ec2e37dfea9c6c9ad643e">00061</a> <span class="preprocessor"></span><span class="preprocessor">#define TOLERANCE 1e-9</span>
<a name="l00062"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#fb6d30e5f89a2a1749e4a9a896716ef4">00062</a> <span class="preprocessor"></span><span class="preprocessor">#define BACKOFF 3.0</span>
<a name="l00063"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#12de296cc2e5fedc31307a31c2f6dc97">00063</a> <span class="preprocessor"></span><span class="preprocessor">#define EXPONENT_BASE 2.0 </span>
<a name="l00064"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#fd63d23830ad86d01b6fff2e6c615f7e">00064</a> <span class="preprocessor"></span><span class="preprocessor">#define MAX_TRIES 16</span>
<a name="l00065"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#b60883baeb411c29907975faef74cb59">00065</a> <span class="preprocessor"></span><span class="preprocessor">#define DOWNHILL_THRESH 0.05</span>
<a name="l00066"></a>00066 <span class="preprocessor"></span>
<a name="l00067"></a>00067 
<a name="l00073"></a>00073 <span class="keyword">class </span><a class="code" href="class_temp.html">Temp</a> : <span class="keyword">public</span> <a class="code" href="classlibpg_1_1_softmax_policy.html">SoftmaxPolicy</a>::<a class="code" href="classlibpg_1_1_softmax_policy_1_1_temperature.html#5dfa54b70da631c6e5866811e8e8845f">Temperature</a> {
<a name="l00074"></a>00074 
<a name="l00075"></a>00075 <span class="keyword">public</span>:
<a name="l00076"></a>00076     
<a name="l00081"></a><a class="code" href="class_temp.html#3cc625d67a057bcfc7f9a93d0fb153e7">00081</a>     <a class="code" href="class_temp.html#3cc625d67a057bcfc7f9a93d0fb153e7">Temp</a>(<span class="keywordtype">double</span> K) {
<a name="l00082"></a>00082         this-&gt;K = K;
<a name="l00083"></a>00083     }
<a name="l00084"></a>00084     
<a name="l00090"></a><a class="code" href="class_temp.html#2abc0b10fea7564e85141119f9e4960f">00090</a>     <span class="keywordtype">double</span> <a class="code" href="class_temp.html#2abc0b10fea7564e85141119f9e4960f">getValue</a>(<span class="keywordtype">int</span> steps) {
<a name="l00091"></a>00091         <span class="keywordflow">return</span> (<span class="keywordtype">double</span>) 1.0 / ((1.0 + K * (double)steps)*(1.0 + K * (double)steps));
<a name="l00092"></a>00092     }
<a name="l00093"></a>00093     
<a name="l00094"></a>00094 <span class="keyword">private</span>:
<a name="l00095"></a>00095     
<a name="l00096"></a>00096     <span class="keywordtype">double</span> K;
<a name="l00097"></a>00097     
<a name="l00098"></a>00098 };
<a name="l00099"></a>00099 
<a name="l00100"></a>00100 
<a name="l00101"></a>00101 <span class="keyword">class </span><a class="code" href="class_epsilon_decay.html">EpsilonDecay</a> : <span class="keyword">public</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>::<a class="code" href="classlibpg_1_1e_greedy_policy_1_1_epsilon_function.html#4341282404ae394d2d5c4fa3fc23c533">EpsilonFunction</a> {
<a name="l00102"></a>00102     
<a name="l00103"></a>00103 <span class="keyword">private</span>:
<a name="l00104"></a>00104     <span class="keywordtype">double</span> K;
<a name="l00105"></a>00105     
<a name="l00106"></a>00106 <span class="keyword">public</span>:
<a name="l00107"></a>00107     
<a name="l00108"></a><a class="code" href="class_epsilon_decay.html#b8fdb0e1f83641adf62044169e869ff3">00108</a>     <a class="code" href="class_epsilon_decay.html#b8fdb0e1f83641adf62044169e869ff3">EpsilonDecay</a>(<span class="keywordtype">double</span> K) {
<a name="l00109"></a>00109         this-&gt;K=K;
<a name="l00110"></a>00110     }
<a name="l00111"></a>00111     
<a name="l00112"></a><a class="code" href="class_epsilon_decay.html#c30b4ea54df6dec9df988f1071f082bc">00112</a>     <span class="keywordtype">double</span> <a class="code" href="class_epsilon_decay.html#c30b4ea54df6dec9df988f1071f082bc">getValue</a>(<span class="keywordtype">int</span> steps) {
<a name="l00113"></a>00113         <span class="keywordflow">return</span> (<span class="keywordtype">double</span>) 1.0 / ((1.0 + K * (double)steps)*(1.0 + K * (double)steps));
<a name="l00114"></a>00114     }
<a name="l00115"></a>00115     
<a name="l00116"></a>00116 };
<a name="l00117"></a>00117 
<a name="l00118"></a>00118 
<a name="l00119"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">00119</a> <span class="preprocessor">#define commonInit() \</span>
<a name="l00120"></a>00120 <span class="preprocessor">    Vector nnDims(NN_LAYERS); \</span>
<a name="l00121"></a>00121 <span class="preprocessor">    nnDims[0] = OBS_DIM; \</span>
<a name="l00122"></a>00122 <span class="preprocessor">    nnDims[1] = APPROX_OUTPUTS; \</span>
<a name="l00123"></a>00123 <span class="preprocessor">    Vector squash(NN_LAYERS); \</span>
<a name="l00124"></a>00124 <span class="preprocessor">    squash.clear();</span>
<a name="l00125"></a>00125 <span class="preprocessor"></span>
<a name="l00126"></a>00126 
<a name="l00132"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#becc2f63e247b6f767ae91ff1abc3d76">00132</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#becc2f63e247b6f767ae91ff1abc3d76">SARSA_NeuralNet_Softmax_Decaying</a>() {
<a name="l00133"></a>00133     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00134"></a>00134 
<a name="l00135"></a>00135 
<a name="l00136"></a>00136     <span class="comment">// With eligibility traces</span>
<a name="l00137"></a>00137     <span class="comment">// Expected reward ~ 2.58</span>
<a name="l00138"></a>00138     <span class="keywordtype">double</span> lambda =  0.4;
<a name="l00139"></a>00139     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.0001;
<a name="l00140"></a>00140     <span class="keywordtype">double</span> kapa =      1e-05;
<a name="l00141"></a>00141 
<a name="l00142"></a>00142     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running SARSA with NeuralNet approximator and Softmax policy with decaying temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00143"></a>00143  
<a name="l00144"></a>00144     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_s_a_r_s_a_controller.html">SARSAController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00145"></a>00145                                                  <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_softmax_policy.html">SoftmaxPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_temp.html">Temp</a>(kapa)),
<a name="l00146"></a>00146                                                  <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00147"></a>00147 
<a name="l00148"></a>00148     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00149"></a>00149 
<a name="l00150"></a>00150 
<a name="l00151"></a>00151 
<a name="l00152"></a>00152     <span class="keywordflow">return</span> learner;
<a name="l00153"></a>00153 }
<a name="l00154"></a>00154 
<a name="l00155"></a>00155 
<a name="l00156"></a>00156 
<a name="l00162"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#8c0e02560da39fcb3ce32d7cdec4a560">00162</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_three_state_2_three_state_test_8cc.html#8c0e02560da39fcb3ce32d7cdec4a560">LSTDQ_NeuralNet_Softmax_Decaying</a>() {
<a name="l00163"></a>00163     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00164"></a>00164 
<a name="l00165"></a>00165     <span class="comment">// With eligibility traces</span>
<a name="l00166"></a>00166     <span class="comment">// Expected reward ~ 2.58</span>
<a name="l00167"></a>00167     <span class="keywordtype">double</span> lambda =  0.0; <span class="comment">// Should be 0.0 for true LSTDQ</span>
<a name="l00168"></a>00168     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.0; <span class="comment">// Ignored</span>
<a name="l00169"></a>00169     <span class="keywordtype">double</span> kapa =      1e-05;
<a name="l00170"></a>00170 
<a name="l00171"></a>00171     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running LSPI with softmax policy with decaying temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00172"></a>00172  
<a name="l00173"></a>00173 
<a name="l00174"></a>00174     <span class="comment">// Note that construction of the basis vectors for LSTDQ implicity produces an OBS_DIM*APPROX_OUTPUTS</span>
<a name="l00175"></a>00175     <span class="comment">// vector, with all 0's except it has a copy of the observation vector at the relevant action</span>
<a name="l00176"></a>00176     <span class="comment">// for whatever action we are approximating the value of.</span>
<a name="l00177"></a>00177     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_l_s_t_d_q_controller.html">LSTDQController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(<a class="code" href="_grid_sim_8cc.html#f80bc950ecebb77deb2747f9a787a95a">OBS_DIM</a>, <a class="code" href="crf_8cc.html#4d21079c4be880d193a8b3b7df9c467b">APPROX_OUTPUTS</a>),
<a name="l00178"></a>00178                                                 (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_softmax_policy.html">SoftmaxPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_temp.html">Temp</a>(kapa)),
<a name="l00179"></a>00179                                                 <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00180"></a>00180 
<a name="l00181"></a>00181     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00182"></a>00182 
<a name="l00183"></a>00183     
<a name="l00184"></a>00184 
<a name="l00185"></a>00185     <span class="keywordflow">return</span> learner;
<a name="l00186"></a>00186 }
<a name="l00187"></a>00187 
<a name="l00188"></a>00188 
<a name="l00194"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#964a58969dc054febcfaa04197754c16">00194</a> <a class="code" href="classlibpg_1_1_g_pomdp.html">GPomdp</a>* <a class="code" href="_template_r_l_app_8cc.html#c9f9d3cf17efd99099a8e2a33b216d0e">LSPI</a>() {
<a name="l00195"></a>00195 
<a name="l00196"></a>00196     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00197"></a>00197 
<a name="l00198"></a>00198     <span class="comment">// With eligibility traces</span>
<a name="l00199"></a>00199     <span class="comment">// Expected reward ~ 2.58</span>
<a name="l00200"></a>00200     <span class="keywordtype">double</span> lambda =  0.0; <span class="comment">// Should be 0.0 for true LSPI</span>
<a name="l00201"></a>00201     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.0; <span class="comment">// Ignored</span>
<a name="l00202"></a>00202     <span class="keywordtype">double</span> epsilon =   0.05; <span class="comment">// 0.0 = greedy</span>
<a name="l00203"></a>00203 
<a name="l00204"></a>00204     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running LSPI with softmax policy with decaying temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00205"></a>00205  
<a name="l00206"></a>00206 
<a name="l00207"></a>00207     <span class="comment">// Note that construction of the basis vectors for LSTDQ implicity produces an OBS_DIM*APPROX_OUTPUTS</span>
<a name="l00208"></a>00208     <span class="comment">// vector, with all 0's except it has a copy of the observation vector at the relevant action</span>
<a name="l00209"></a>00209     <span class="comment">// for whatever action we are approximating the value of.</span>
<a name="l00210"></a>00210     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_l_s_t_d_q_controller.html">LSTDQController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(<a class="code" href="_grid_sim_8cc.html#f80bc950ecebb77deb2747f9a787a95a">OBS_DIM</a>, <a class="code" href="crf_8cc.html#4d21079c4be880d193a8b3b7df9c467b">APPROX_OUTPUTS</a>),
<a name="l00211"></a>00211                                                  <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(epsilon),
<a name="l00212"></a>00212                                                 <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00213"></a>00213 
<a name="l00214"></a>00214     <span class="comment">// THe only difference between online LSTDQ learning, and LSPI, is</span>
<a name="l00215"></a>00215     <span class="comment">// the use of the GPOMDP batch algorithm in the line below and the</span>
<a name="l00216"></a>00216     <span class="comment">// epsilon greedy policy</span>
<a name="l00217"></a>00217     <a class="code" href="classlibpg_1_1_g_pomdp.html">GPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_g_pomdp.html">GPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00218"></a>00218 
<a name="l00219"></a>00219 
<a name="l00220"></a>00220 
<a name="l00221"></a>00221     <span class="keywordflow">return</span> learner;
<a name="l00222"></a>00222 }
<a name="l00223"></a>00223 
<a name="l00224"></a>00224 
<a name="l00225"></a>00225 
<a name="l00231"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#9771ff6ecc40282478201ec8b1f068aa">00231</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#9771ff6ecc40282478201ec8b1f068aa">SARSA_NeuralNet_eGreedy_Constant</a>() {
<a name="l00232"></a>00232     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00233"></a>00233 
<a name="l00234"></a>00234     <span class="comment">// Expected reward ~ 2.5</span>
<a name="l00235"></a>00235     <span class="keywordtype">double</span> lambda =  0.5;
<a name="l00236"></a>00236     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00237"></a>00237     <span class="keywordtype">double</span> epsilon =   0.01;
<a name="l00238"></a>00238   
<a name="l00239"></a>00239     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running SARSA with NeuralNet approximator and e-Greedy policy with constant epsilon:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00240"></a>00240 
<a name="l00241"></a>00241     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller= <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_s_a_r_s_a_controller.html">SARSAController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00242"></a>00242                                                 (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(epsilon),
<a name="l00243"></a>00243                                                 <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00244"></a>00244 
<a name="l00245"></a>00245     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00246"></a>00246 
<a name="l00247"></a>00247     
<a name="l00248"></a>00248 
<a name="l00249"></a>00249     <span class="keywordflow">return</span> learner;
<a name="l00250"></a>00250 }
<a name="l00251"></a>00251 
<a name="l00252"></a>00252 
<a name="l00258"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#431d4c751d9c2039659207c24eb8812e">00258</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#431d4c751d9c2039659207c24eb8812e">SARSA_NeuralNet_eGreedy_Decaying</a>() {
<a name="l00259"></a>00259     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00260"></a>00260 
<a name="l00261"></a>00261     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00262"></a>00262     <span class="keywordtype">double</span> lambda =  0.7;
<a name="l00263"></a>00263     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00264"></a>00264     <span class="keywordtype">double</span> kapa =      0.001;
<a name="l00265"></a>00265   
<a name="l00266"></a>00266     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running SARSA with NeuralNet approximator and e-Greedy policy with decaying epsilon:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00267"></a>00267 
<a name="l00268"></a>00268     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_s_a_r_s_a_controller.html">SARSAController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00269"></a>00269                                                  (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_epsilon_decay.html">EpsilonDecay</a>(kapa)),
<a name="l00270"></a>00270                                                  <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00271"></a>00271 
<a name="l00272"></a>00272     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00273"></a>00273 
<a name="l00274"></a>00274     
<a name="l00275"></a>00275 
<a name="l00276"></a>00276     <span class="keywordflow">return</span> learner;
<a name="l00277"></a>00277 }
<a name="l00278"></a>00278 
<a name="l00279"></a>00279 
<a name="l00285"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#477f5c611b58b35c1ad49d4a77652ca6">00285</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#477f5c611b58b35c1ad49d4a77652ca6">QLearning_NeuralNet_Softmax_Decaying</a>() {
<a name="l00286"></a>00286 
<a name="l00287"></a>00287     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00288"></a>00288 
<a name="l00289"></a>00289     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00290"></a>00290     <span class="keywordtype">double</span> lambda =  0.4;
<a name="l00291"></a>00291     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00292"></a>00292     <span class="keywordtype">double</span> kapa =      1e-05;
<a name="l00293"></a>00293   
<a name="l00294"></a>00294     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running QLearning with NeuralNet approximator and Softmax policy with decaying temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00295"></a>00295 
<a name="l00296"></a>00296     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_q_learning_controller.html">QLearningController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00297"></a>00297                                                      (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_softmax_policy.html">SoftmaxPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_temp.html">Temp</a>(kapa)),
<a name="l00298"></a>00298                                                      <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00299"></a>00299 
<a name="l00300"></a>00300     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00301"></a>00301 
<a name="l00302"></a>00302     
<a name="l00303"></a>00303 
<a name="l00304"></a>00304     <span class="keywordflow">return</span> learner;
<a name="l00305"></a>00305 }
<a name="l00306"></a>00306 
<a name="l00307"></a>00307 
<a name="l00313"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#a216cc990b9186296e1a5bb256e17b9f">00313</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#a216cc990b9186296e1a5bb256e17b9f">QLearning_NeuralNet_eGreedy_Constant</a>() {
<a name="l00314"></a>00314     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00315"></a>00315 
<a name="l00316"></a>00316     <span class="comment">// Expected reward ~ 2.5</span>
<a name="l00317"></a>00317     <span class="keywordtype">double</span> lambda =  0.5;
<a name="l00318"></a>00318     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00319"></a>00319     <span class="keywordtype">double</span> epsilon =   0.01;
<a name="l00320"></a>00320   
<a name="l00321"></a>00321     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running QLearning with NeuralNet approximator and e-Greedy policy with constant temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00322"></a>00322 
<a name="l00323"></a>00323     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_q_learning_controller.html">QLearningController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00324"></a>00324                                                      (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(epsilon),
<a name="l00325"></a>00325                                                      <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00326"></a>00326 
<a name="l00327"></a>00327     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00328"></a>00328 
<a name="l00329"></a>00329     
<a name="l00330"></a>00330 
<a name="l00331"></a>00331     <span class="keywordflow">return</span> learner;
<a name="l00332"></a>00332 }
<a name="l00333"></a>00333 
<a name="l00334"></a>00334 
<a name="l00340"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#ac281e0f52bdd877cd62a331747543e3">00340</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#ac281e0f52bdd877cd62a331747543e3">QLearning_NeuralNet_eGreedy_Decaying</a>() {
<a name="l00341"></a>00341 
<a name="l00342"></a>00342     <a class="code" href="_tao_project_2_three_state_test_8cc.html#1fd76db6eb3601e7eeb373d89a47944a">commonInit</a>();
<a name="l00343"></a>00343 
<a name="l00344"></a>00344     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00345"></a>00345     <span class="keywordtype">double</span> lambda =  0.4;
<a name="l00346"></a>00346     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00347"></a>00347     <span class="keywordtype">double</span> kapa =      0.001;
<a name="l00348"></a>00348   
<a name="l00349"></a>00349     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running QLearning with NeuralNet approximator and e-Greedy policy with decaying temperature:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00350"></a>00350 
<a name="l00351"></a>00351     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_q_learning_controller.html">QLearningController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(nnDims, squash),
<a name="l00352"></a>00352                                                      (<a class="code" href="classlibpg_1_1_policy.html">Policy</a>*) <span class="keyword">new</span> <a class="code" href="classlibpg_1_1e_greedy_policy.html">eGreedyPolicy</a>(<span class="keyword">new</span> <a class="code" href="class_epsilon_decay.html">EpsilonDecay</a>(kapa)),
<a name="l00353"></a>00353                                                      <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00354"></a>00354 
<a name="l00355"></a>00355     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00356"></a>00356 
<a name="l00357"></a>00357     
<a name="l00358"></a>00358 
<a name="l00359"></a>00359     <span class="keywordflow">return</span> learner;
<a name="l00360"></a>00360 }
<a name="l00361"></a>00361 
<a name="l00362"></a>00362 
<a name="l00363"></a>00363 
<a name="l00369"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#4f518506f50a80f13d99bd3e93e2b109">00369</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_three_state_2_three_state_test_8cc.html#4f518506f50a80f13d99bd3e93e2b109">Binary_NeuralNet</a>() {
<a name="l00370"></a>00370    
<a name="l00371"></a>00371     <span class="comment">// commonInit(); Not needed due to use of simple NeuralNet constructor</span>
<a name="l00372"></a>00372 
<a name="l00373"></a>00373     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00374"></a>00374     <span class="keywordtype">double</span> lambda =  0.6;
<a name="l00375"></a>00375     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00376"></a>00376   
<a name="l00377"></a>00377     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running Binary controller with NeuralNet approximator:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00378"></a>00378 
<a name="l00379"></a>00379     <span class="comment">// Note the simplified NeuralNet constructor for creating a linear</span>
<a name="l00380"></a>00380     <span class="comment">// approximator. BinaryController requires it's approximator to</span>
<a name="l00381"></a>00381     <span class="comment">// have only 1 output dimension.</span>
<a name="l00382"></a>00382     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(<a class="code" href="_grid_sim_8cc.html#f80bc950ecebb77deb2747f9a787a95a">OBS_DIM</a>, 1));
<a name="l00383"></a>00383 
<a name="l00384"></a>00384     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00385"></a>00385 
<a name="l00386"></a>00386     
<a name="l00387"></a>00387 
<a name="l00388"></a>00388     <span class="keywordflow">return</span> learner;
<a name="l00389"></a>00389 }
<a name="l00390"></a>00390 
<a name="l00391"></a>00391 
<a name="l00396"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#2d625379d853bfd2ce727bb562cea5e1">00396</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#2d625379d853bfd2ce727bb562cea5e1">NACTransform_Binary_NeuralNet</a>() {
<a name="l00397"></a>00397 
<a name="l00398"></a>00398     <span class="comment">// commonInit();</span>
<a name="l00399"></a>00399 
<a name="l00400"></a>00400     <span class="comment">// Expected reward ~ 2.6</span>
<a name="l00401"></a>00401     <span class="keywordtype">double</span> lambda =  0.4;
<a name="l00402"></a>00402     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00403"></a>00403   
<a name="l00404"></a>00404     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running Binary controller with NeuralNet approximator:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00405"></a>00405 
<a name="l00406"></a>00406     <span class="comment">// Again BinaryController assumes only 2 actions. Use BasicController otherwise.</span>
<a name="l00407"></a>00407     <a class="code" href="classlibpg_1_1_controller.html">Controller</a>* controller= <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_n_a_c_transform.html">NACTransform</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net_batch.html">NeuralNetBatch</a>(<a class="code" href="_grid_sim_8cc.html#f80bc950ecebb77deb2747f9a787a95a">OBS_DIM</a>, 1)), <a class="code" href="options_8hh.html#df579b0668a161d0ac966509f378a08d">TD_DISCOUNT</a>);
<a name="l00408"></a>00408 
<a name="l00409"></a>00409     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(controller, <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00410"></a>00410 
<a name="l00411"></a>00411     <span class="keywordflow">return</span> learner;
<a name="l00412"></a>00412 }
<a name="l00413"></a>00413 
<a name="l00419"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#8476e95db07392daa62c2853e60e71a3">00419</a> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* <a class="code" href="_tao_project_2_three_state_test_8cc.html#8476e95db07392daa62c2853e60e71a3">Factored_Binary_NeuralNet</a>() {
<a name="l00420"></a>00420     <span class="comment">// commonInit();</span>
<a name="l00421"></a>00421 
<a name="l00422"></a>00422     <span class="comment">// Expected reward ~ 2.5</span>
<a name="l00423"></a>00423     <span class="keywordtype">double</span> lambda =  0.8;
<a name="l00424"></a>00424     <span class="keywordtype">double</span> <a class="code" href="namespacemerge_processor_optimisator_output.html#f089e13896338c3e423a2b18be1b67cd">step_size</a> = 0.001;
<a name="l00425"></a>00425   
<a name="l00426"></a>00426     cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">"Running Binary controller with NeuralNet approximator:"</span> &lt;&lt; endl &lt;&lt; endl;
<a name="l00427"></a>00427 
<a name="l00428"></a>00428     <span class="comment">// Create one controller per agent.</span>
<a name="l00429"></a>00429     FactoredController::Controllers controllers;
<a name="l00430"></a>00430     controllers.push_back(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_binary_controller.html">BinaryController</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_neural_net.html">NeuralNet</a>(<a class="code" href="_grid_sim_8cc.html#f80bc950ecebb77deb2747f9a787a95a">OBS_DIM</a>, 1)));
<a name="l00431"></a>00431 
<a name="l00432"></a>00432     <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>* learner = <span class="keyword">new</span> <a class="code" href="classlibpg_1_1_o_l_pomdp.html">OLPomdp</a>(<span class="keyword">new</span> <a class="code" href="classlibpg_1_1_factored_controller.html">FactoredController</a>(controllers, <span class="keyword">false</span>, <span class="keyword">false</span>), <span class="keyword">new</span> <a class="code" href="class_three_state.html">ThreeState</a>(), lambda, step_size);
<a name="l00433"></a>00433 
<a name="l00434"></a>00434     
<a name="l00435"></a>00435 
<a name="l00436"></a>00436     <span class="keywordflow">return</span> learner;
<a name="l00437"></a>00437 }
<a name="l00438"></a>00438 
<a name="l00439"></a>00439 
<a name="l00440"></a>00440 
<a name="l00445"></a><a class="code" href="_three_state_2_three_state_test_8cc.html#3c04138a5bfe5d72780bb7e82a18e627">00445</a> <span class="keywordtype">int</span> <a class="code" href="_cassandra_test_8cc.html#3c04138a5bfe5d72780bb7e82a18e627">main</a>(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>** argv) {
<a name="l00446"></a>00446 
<a name="l00447"></a>00447     <a class="code" href="classlibpg_1_1_r_l_alg.html">RLAlg</a>* learner = NULL;
<a name="l00448"></a>00448     time_t startTime = time(NULL);
<a name="l00449"></a>00449  
<a name="l00450"></a>00450 
<a name="l00451"></a>00451     <span class="keywordflow">if</span> (argc &gt; 1) {
<a name="l00452"></a>00452 
<a name="l00453"></a>00453         <span class="keywordflow">switch</span> (atoi(argv[1])) {
<a name="l00454"></a>00454 
<a name="l00455"></a>00455             <span class="keywordflow">case</span> 1:
<a name="l00456"></a>00456                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#becc2f63e247b6f767ae91ff1abc3d76">SARSA_NeuralNet_Softmax_Decaying</a>();
<a name="l00457"></a>00457                 <span class="keywordflow">break</span>;
<a name="l00458"></a>00458 
<a name="l00459"></a>00459             <span class="keywordflow">case</span> 2:
<a name="l00460"></a>00460                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#9771ff6ecc40282478201ec8b1f068aa">SARSA_NeuralNet_eGreedy_Constant</a>();
<a name="l00461"></a>00461                 <span class="keywordflow">break</span>;
<a name="l00462"></a>00462 
<a name="l00463"></a>00463             <span class="keywordflow">case</span> 3:
<a name="l00464"></a>00464                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#431d4c751d9c2039659207c24eb8812e">SARSA_NeuralNet_eGreedy_Decaying</a>();
<a name="l00465"></a>00465                 <span class="keywordflow">break</span>;
<a name="l00466"></a>00466 
<a name="l00467"></a>00467             <span class="keywordflow">case</span> 4:
<a name="l00468"></a>00468                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#477f5c611b58b35c1ad49d4a77652ca6">QLearning_NeuralNet_Softmax_Decaying</a>();
<a name="l00469"></a>00469                 <span class="keywordflow">break</span>;
<a name="l00470"></a>00470 
<a name="l00471"></a>00471             <span class="keywordflow">case</span> 5:
<a name="l00472"></a>00472                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#a216cc990b9186296e1a5bb256e17b9f">QLearning_NeuralNet_eGreedy_Constant</a>();
<a name="l00473"></a>00473                 <span class="keywordflow">break</span>;
<a name="l00474"></a>00474 
<a name="l00475"></a>00475             <span class="keywordflow">case</span> 6:
<a name="l00476"></a>00476                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#ac281e0f52bdd877cd62a331747543e3">QLearning_NeuralNet_eGreedy_Decaying</a>();
<a name="l00477"></a>00477                 <span class="keywordflow">break</span>;
<a name="l00478"></a>00478 
<a name="l00479"></a>00479             <span class="keywordflow">case</span> 7:
<a name="l00480"></a>00480                 learner = <a class="code" href="_three_state_2_three_state_test_8cc.html#4f518506f50a80f13d99bd3e93e2b109">Binary_NeuralNet</a>();
<a name="l00481"></a>00481                 <span class="keywordflow">break</span>;
<a name="l00482"></a>00482 
<a name="l00483"></a>00483             <span class="keywordflow">case</span> 8:
<a name="l00484"></a>00484                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#2d625379d853bfd2ce727bb562cea5e1">NACTransform_Binary_NeuralNet</a>();
<a name="l00485"></a>00485                 <span class="keywordflow">break</span>;
<a name="l00486"></a>00486 
<a name="l00487"></a>00487             <span class="keywordflow">case</span> 9:
<a name="l00488"></a>00488                 learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#8476e95db07392daa62c2853e60e71a3">Factored_Binary_NeuralNet</a>();
<a name="l00489"></a>00489                 <span class="keywordflow">break</span>;
<a name="l00490"></a>00490 
<a name="l00491"></a>00491             <span class="keywordflow">case</span> 10:
<a name="l00492"></a>00492                 learner = <a class="code" href="_three_state_2_three_state_test_8cc.html#8c0e02560da39fcb3ce32d7cdec4a560">LSTDQ_NeuralNet_Softmax_Decaying</a>();
<a name="l00493"></a>00493                 <span class="keywordflow">break</span>;
<a name="l00494"></a>00494 
<a name="l00495"></a>00495             <span class="keywordflow">case</span> 11:
<a name="l00496"></a>00496                 learner = <a class="code" href="_template_r_l_app_8cc.html#c9f9d3cf17efd99099a8e2a33b216d0e">LSPI</a>();
<a name="l00497"></a>00497                 <span class="keywordflow">break</span>;
<a name="l00498"></a>00498 
<a name="l00499"></a>00499             <span class="keywordflow">default</span>:
<a name="l00500"></a>00500                 cout &lt;&lt; <span class="stringliteral">"Invalid option!"</span> &lt;&lt; endl;
<a name="l00501"></a>00501                 <span class="keywordflow">break</span>;
<a name="l00502"></a>00502         }
<a name="l00503"></a>00503         
<a name="l00504"></a>00504         <span class="keywordflow">if</span> (learner != NULL) {
<a name="l00505"></a>00505             learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00506"></a>00506             <span class="keyword">delete</span> learner;  
<a name="l00507"></a>00507         }
<a name="l00508"></a>00508     }
<a name="l00509"></a>00509     <span class="keywordflow">else</span> {
<a name="l00510"></a>00510         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#becc2f63e247b6f767ae91ff1abc3d76">SARSA_NeuralNet_Softmax_Decaying</a>();
<a name="l00511"></a>00511         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00512"></a>00512         <span class="keyword">delete</span> learner;
<a name="l00513"></a>00513 
<a name="l00514"></a>00514         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#9771ff6ecc40282478201ec8b1f068aa">SARSA_NeuralNet_eGreedy_Constant</a>();
<a name="l00515"></a>00515         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00516"></a>00516         <span class="keyword">delete</span> learner;
<a name="l00517"></a>00517 
<a name="l00518"></a>00518         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#431d4c751d9c2039659207c24eb8812e">SARSA_NeuralNet_eGreedy_Decaying</a>();
<a name="l00519"></a>00519         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00520"></a>00520         <span class="keyword">delete</span> learner;
<a name="l00521"></a>00521 
<a name="l00522"></a>00522         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#477f5c611b58b35c1ad49d4a77652ca6">QLearning_NeuralNet_Softmax_Decaying</a>();
<a name="l00523"></a>00523         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00524"></a>00524         <span class="keyword">delete</span> learner;
<a name="l00525"></a>00525 
<a name="l00526"></a>00526         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#a216cc990b9186296e1a5bb256e17b9f">QLearning_NeuralNet_eGreedy_Constant</a>();
<a name="l00527"></a>00527         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00528"></a>00528         <span class="keyword">delete</span> learner;
<a name="l00529"></a>00529 
<a name="l00530"></a>00530         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#ac281e0f52bdd877cd62a331747543e3">QLearning_NeuralNet_eGreedy_Decaying</a>();
<a name="l00531"></a>00531         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00532"></a>00532         <span class="keyword">delete</span> learner;
<a name="l00533"></a>00533 
<a name="l00534"></a>00534         learner = <a class="code" href="_three_state_2_three_state_test_8cc.html#8c0e02560da39fcb3ce32d7cdec4a560">LSTDQ_NeuralNet_Softmax_Decaying</a>();
<a name="l00535"></a>00535         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00536"></a>00536         <span class="keyword">delete</span> learner;
<a name="l00537"></a>00537 
<a name="l00538"></a>00538         learner = <a class="code" href="_template_r_l_app_8cc.html#c9f9d3cf17efd99099a8e2a33b216d0e">LSPI</a>();
<a name="l00539"></a>00539         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00540"></a>00540         <span class="keyword">delete</span> learner;
<a name="l00541"></a>00541 
<a name="l00542"></a>00542         learner = <a class="code" href="_three_state_2_three_state_test_8cc.html#4f518506f50a80f13d99bd3e93e2b109">Binary_NeuralNet</a>();
<a name="l00543"></a>00543         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00544"></a>00544         <span class="keyword">delete</span> learner;
<a name="l00545"></a>00545 
<a name="l00546"></a>00546         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#2d625379d853bfd2ce727bb562cea5e1">NACTransform_Binary_NeuralNet</a>();
<a name="l00547"></a>00547         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00548"></a>00548         <span class="keyword">delete</span> learner;
<a name="l00549"></a>00549         
<a name="l00550"></a>00550         learner = <a class="code" href="_tao_project_2_three_state_test_8cc.html#8476e95db07392daa62c2853e60e71a3">Factored_Binary_NeuralNet</a>();
<a name="l00551"></a>00551         learner-&gt;<a class="code" href="classlibpg_1_1_r_l_alg.html#8cff16a2d53a5909e8518648078807c7">learn</a>(<a class="code" href="options_8hh.html#8c324bb806c51b79c1e30b5a3c80d3fe">STEPS_PER_EPOCH</a>, <a class="code" href="options_8hh.html#5320d4457a472d8888ec1905bc0e0a1c">MAX_TIME</a>, <a class="code" href="options_8hh.html#a0414caef00a64a51d4c6c0711d9e70a">MAX_STEPS</a>);
<a name="l00552"></a>00552         <span class="keyword">delete</span> learner;
<a name="l00553"></a>00553     }
<a name="l00554"></a>00554 
<a name="l00555"></a>00555     cout&lt;&lt;<span class="stringliteral">"Took "</span>&lt;&lt;time(NULL) - startTime&lt;&lt;<span class="stringliteral">" secs\n"</span>;
<a name="l00556"></a>00556 
<a name="l00557"></a>00557     <span class="keywordflow">return</span> 0;
<a name="l00558"></a>00558 }
</pre></div><hr size="1"><address style="text-align: right;"><small>Generated on Mon Sep 10 19:32:09 2007 for The PG Library by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.5.3 </small></address>
</body>
</html>
